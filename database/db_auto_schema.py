"""
è‡ªåŠ¨æ•°æ®åº“æ¶æ„ç®¡ç†å™¨
æ ¹æ®Pythonä»£ç ä¸­çš„æ•°æ®åº“æ“ä½œè‡ªåŠ¨æ¨æ–­å’Œåˆ›å»ºè¡¨ç»“æ„
"""

import os
import re
import ast
import logging
import importlib
from typing import Dict, List, Set, Tuple, Any, Optional
from datetime import datetime
from .db_connection import db_manager
from pathmanager import PathManager

logger = logging.getLogger(__name__)

class SchemaField:
    """æ•°æ®åº“å­—æ®µå®šä¹‰"""
    def __init__(self, name: str, type_: str, nullable: bool = True, 
                 primary_key: bool = False, unique: bool = False, 
                 default: Any = None):
        self.name = name
        self.type = type_
        self.nullable = nullable
        self.primary_key = primary_key
        self.unique = unique
        self.default = default
    
    def to_sql(self) -> str:
        """è½¬æ¢ä¸ºSQLå®šä¹‰"""
        sql = f"{self.name} {self.type}"
        
        if self.primary_key:
            sql += " PRIMARY KEY"
            if self.type.upper() == "INTEGER":
                sql += " AUTOINCREMENT"
        
        if not self.nullable and not self.primary_key:
            sql += " NOT NULL"
        
        if self.unique and not self.primary_key:
            sql += " UNIQUE"
        
        if self.default is not None:
            if isinstance(self.default, str):
                sql += f" DEFAULT '{self.default}'"
            else:
                sql += f" DEFAULT {self.default}"
        
        return sql

class TableSchema:
    """æ•°æ®åº“è¡¨æ¶æ„"""
    def __init__(self, name: str):
        self.name = name
        self.fields: List[SchemaField] = []
        self.indexes: List[str] = []
        self.foreign_keys: List[str] = []
    
    def add_field(self, field: SchemaField):
        """æ·»åŠ å­—æ®µ"""
        self.fields.append(field)
    
    def add_index(self, columns: List[str], unique: bool = False):
        """æ·»åŠ ç´¢å¼•"""
        index_type = "UNIQUE INDEX" if unique else "INDEX"
        index_name = f"idx_{self.name}_{'_'.join(columns)}"
        self.indexes.append(f"CREATE {index_type} {index_name} ON {self.name} ({', '.join(columns)})")
    
    def to_sql(self) -> str:
        """è½¬æ¢ä¸ºCREATE TABLE SQLè¯­å¥"""
        if not self.fields:
            return ""
        
        field_definitions = [field.to_sql() for field in self.fields]
        
        sql = f"CREATE TABLE IF NOT EXISTS {self.name} (\n"
        sql += ",\n".join(f"    {field_def}" for field_def in field_definitions)
        
        if self.foreign_keys:
            sql += ",\n" + ",\n".join(f"    {fk}" for fk in self.foreign_keys)
        
        sql += "\n)"
        
        return sql

class AutoSchemaManager:
    """è‡ªåŠ¨æ¶æ„ç®¡ç†å™¨"""
    
    def __init__(self):
        self.schemas: Dict[str, TableSchema] = {}
        self.database_dir = PathManager.get_database_directory()
    
    async def analyze_codebase(self) -> Dict[str, TableSchema]:
        """åˆ†æä»£ç åº“å¹¶æ¨æ–­è¡¨ç»“æ„"""
        logger.info("å¼€å§‹åˆ†æä»£ç åº“ï¼Œæ¨æ–­æ•°æ®åº“è¡¨ç»“æ„...")
        
        # åˆ†ææ‰€æœ‰æ•°æ®åº“æ“ä½œæ–‡ä»¶
        db_files = [f for f in os.listdir(self.database_dir) 
                   if f.startswith('db_') and f.endswith('.py') and f != 'db_auto_schema.py']
        
        for db_file in db_files:
            logger.info(f"åˆ†ææ–‡ä»¶: {db_file}")
            await self._analyze_db_file(db_file)
        
        # æ‰‹åŠ¨å®šä¹‰ä¸€äº›æ ¸å¿ƒè¡¨ç»“æ„ï¼ˆåŸºäºå®é™…ä½¿ç”¨æ¨¡å¼ï¼‰
        await self._define_core_schemas()
        
        logger.info(f"åˆ†æå®Œæˆï¼Œå‘ç° {len(self.schemas)} ä¸ªè¡¨")
        return self.schemas
    
    async def _analyze_db_file(self, filename: str):
        """åˆ†æå•ä¸ªæ•°æ®åº“æ–‡ä»¶"""
        file_path = os.path.join(self.database_dir, filename)
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾SQLæŸ¥è¯¢ä¸­çš„è¡¨åå’Œå­—æ®µ
            await self._extract_sql_patterns(content)
            
        except Exception as e:
            logger.warning(f"åˆ†ææ–‡ä»¶ {filename} å¤±è´¥: {e}")
    
    async def _extract_sql_patterns(self, content: str):
        """ä»ä»£ç ä¸­æå–SQLæ¨¡å¼"""
        # æŸ¥æ‰¾INSERTè¯­å¥
        insert_pattern = r'INSERT\s+(?:OR\s+\w+\s+)?INTO\s+(\w+)\s*\((.*?)\)\s*VALUES'
        insert_matches = re.finditer(insert_pattern, content, re.IGNORECASE | re.DOTALL)
        
        for match in insert_matches:
            table_name = match.group(1)
            columns = [col.strip() for col in match.group(2).split(',')]
            await self._update_table_schema(table_name, columns)
        
        # æŸ¥æ‰¾UPDATEè¯­å¥
        update_pattern = r'UPDATE\s+(\w+)\s+SET\s+(.*?)\s+WHERE'
        update_matches = re.finditer(update_pattern, content, re.IGNORECASE | re.DOTALL)
        
        for match in update_matches:
            table_name = match.group(1)
            set_clause = match.group(2)
            columns = [col.split('=')[0].strip() for col in set_clause.split(',')]
            await self._update_table_schema(table_name, columns)
        
        # æŸ¥æ‰¾SELECTè¯­å¥ä¸­çš„è¡¨å
        select_pattern = r'SELECT\s+.*?\s+FROM\s+(\w+)'
        select_matches = re.finditer(select_pattern, content, re.IGNORECASE)
        
        for match in select_matches:
            table_name = match.group(1)
            if table_name not in self.schemas:
                self.schemas[table_name] = TableSchema(table_name)
    
    async def _update_table_schema(self, table_name: str, columns: List[str]):
        """æ›´æ–°è¡¨æ¶æ„"""
        if table_name not in self.schemas:
            self.schemas[table_name] = TableSchema(table_name)
        
        schema = self.schemas[table_name]
        existing_fields = {field.name for field in schema.fields}
        
        for column in columns:
            column = column.strip()
            if column and column not in existing_fields:
                # æ ¹æ®å­—æ®µåæ¨æ–­ç±»å‹
                field_type = self._infer_field_type(column)
                schema.add_field(SchemaField(column, field_type))
    
    def _infer_field_type(self, field_name: str) -> str:
        """æ ¹æ®å­—æ®µåæ¨æ–­æ•°æ®ç±»å‹"""
        field_name = field_name.lower()
        
        # IDå­—æ®µ
        if field_name in ['id', 'merchant_id', 'user_id', 'chat_id', 'order_id', 'trigger_id', 'message_id']:
            return "INTEGER"
        
        # æ—¶é—´å­—æ®µ
        if any(time_word in field_name for time_word in ['timestamp', 'created_at', 'updated_at', 'expires_at', 'date']):
            return "TIMESTAMP"
        
        # å¸ƒå°”å­—æ®µ
        if any(bool_word in field_name for bool_word in ['is_', 'has_', 'enabled', 'active']):
            return "BOOLEAN"
        
        # è®¡æ•°å­—æ®µ
        if any(count_word in field_name for count_word in ['count', 'num_', 'total_', 'amount']):
            return "INTEGER"
        
        # çŠ¶æ€å­—æ®µï¼ˆé€šå¸¸è¾ƒçŸ­ï¼‰
        if field_name in ['status', 'type', 'category', 'region']:
            return "VARCHAR(50)"
        
        # åç§°å­—æ®µ
        if 'name' in field_name or field_name in ['title', 'subject']:
            return "VARCHAR(255)"
        
        # é•¿æ–‡æœ¬å­—æ®µ
        if any(text_word in field_name for text_word in ['content', 'description', 'details', 'data', 'profile_data']):
            return "TEXT"
        
        # é»˜è®¤ä¸ºæ–‡æœ¬
        return "TEXT"
    
    async def _define_core_schemas(self):
        """å®šä¹‰æ ¸å¿ƒè¡¨ç»“æ„ï¼ˆåŸºäºå®é™…ä¸šåŠ¡éœ€æ±‚ï¼‰"""
        
        # å•†æˆ·è¡¨
        merchants = TableSchema("merchants")
        merchants.add_field(SchemaField("id", "INTEGER", primary_key=True))
        merchants.add_field(SchemaField("chat_id", "INTEGER", nullable=False, unique=True))
        merchants.add_field(SchemaField("name", "VARCHAR(255)", nullable=False))
        merchants.add_field(SchemaField("region", "VARCHAR(100)"))
        merchants.add_field(SchemaField("category", "VARCHAR(100)"))
        merchants.add_field(SchemaField("contact_info", "TEXT"))
        merchants.add_field(SchemaField("profile_data", "TEXT"))
        merchants.add_field(SchemaField("status", "VARCHAR(20)", default="pending"))
        merchants.add_field(SchemaField("binding_code", "VARCHAR(20)"))
        merchants.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        merchants.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        # æ–°ä¸Šæ¦œæµç¨‹æ‰©å±•å­—æ®µ
        merchants.add_field(SchemaField("merchant_type", "TEXT", default="teacher"))
        merchants.add_field(SchemaField("city_id", "INTEGER"))
        merchants.add_field(SchemaField("district_id", "INTEGER"))
        merchants.add_field(SchemaField("p_price", "INTEGER"))
        merchants.add_field(SchemaField("pp_price", "INTEGER"))
        merchants.add_field(SchemaField("custom_description", "TEXT"))
        merchants.add_field(SchemaField("user_info", "TEXT"))
        merchants.add_field(SchemaField("channel_link", "TEXT"))
        merchants.add_index(["chat_id"], unique=True)
        merchants.add_index(["status"])
        merchants.add_index(["binding_code"])
        merchants.add_index(["city_id"])
        merchants.add_index(["district_id"])
        merchants.add_index(["merchant_type"])
        self.schemas["merchants"] = merchants
        
        # è®¢å•è¡¨
        orders = TableSchema("orders")
        orders.add_field(SchemaField("id", "INTEGER", primary_key=True))
        orders.add_field(SchemaField("merchant_id", "INTEGER", nullable=False))
        orders.add_field(SchemaField("user_id", "INTEGER", nullable=False))
        orders.add_field(SchemaField("chat_id", "INTEGER", nullable=False))
        orders.add_field(SchemaField("order_type", "VARCHAR(50)"))  # æ·»åŠ è®¢å•ç±»å‹
        orders.add_field(SchemaField("order_data", "TEXT"))
        orders.add_field(SchemaField("status", "VARCHAR(20)", default="pending"))
        orders.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        orders.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        orders.foreign_keys.append("FOREIGN KEY (merchant_id) REFERENCES merchants(id)")
        orders.add_index(["merchant_id"])
        orders.add_index(["user_id"])
        orders.add_index(["status"])
        orders.add_index(["order_type"])
        self.schemas["orders"] = orders
        
        # ç»‘å®šç è¡¨
        binding_codes = TableSchema("binding_codes")
        binding_codes.add_field(SchemaField("id", "INTEGER", primary_key=True))
        binding_codes.add_field(SchemaField("code", "VARCHAR(20)", nullable=False, unique=True))
        binding_codes.add_field(SchemaField("merchant_id", "INTEGER"))
        binding_codes.add_field(SchemaField("is_used", "BOOLEAN", default="FALSE"))
        binding_codes.add_field(SchemaField("used_by_user_id", "INTEGER"))
        binding_codes.add_field(SchemaField("expires_at", "TIMESTAMP"))
        binding_codes.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        binding_codes.add_field(SchemaField("used_at", "TIMESTAMP"))
        binding_codes.add_index(["code"], unique=True)
        binding_codes.add_index(["is_used"])
        binding_codes.add_index(["expires_at"])
        self.schemas["binding_codes"] = binding_codes
        
        # æ´»åŠ¨æ—¥å¿—è¡¨
        activity_logs = TableSchema("activity_logs")
        activity_logs.add_field(SchemaField("id", "INTEGER", primary_key=True))
        activity_logs.add_field(SchemaField("user_id", "INTEGER", nullable=False))
        activity_logs.add_field(SchemaField("action_type", "VARCHAR(50)", nullable=False))
        activity_logs.add_field(SchemaField("details", "TEXT"))
        activity_logs.add_field(SchemaField("timestamp", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        activity_logs.add_field(SchemaField("merchant_id", "INTEGER"))
        activity_logs.add_field(SchemaField("button_id", "INTEGER"))
        activity_logs.add_index(["user_id"])
        activity_logs.add_index(["action_type"])
        activity_logs.add_index(["timestamp"])
        activity_logs.add_index(["merchant_id"])
        self.schemas["activity_logs"] = activity_logs
        
        # FSMçŠ¶æ€è¡¨
        fsm_states = TableSchema("fsm_states")
        fsm_states.add_field(SchemaField("id", "INTEGER", primary_key=True))
        fsm_states.add_field(SchemaField("user_id", "INTEGER", nullable=False, unique=True))
        fsm_states.add_field(SchemaField("state", "VARCHAR(100)"))
        fsm_states.add_field(SchemaField("data", "TEXT"))
        fsm_states.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        fsm_states.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        fsm_states.add_index(["user_id"], unique=True)
        self.schemas["fsm_states"] = fsm_states
        
        # ç³»ç»Ÿé…ç½®è¡¨
        system_config = TableSchema("system_config")
        system_config.add_field(SchemaField("id", "INTEGER", primary_key=True))
        system_config.add_field(SchemaField("config_key", "VARCHAR(100)", nullable=False, unique=True))
        system_config.add_field(SchemaField("config_value", "TEXT"))
        system_config.add_field(SchemaField("description", "TEXT"))
        system_config.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        system_config.add_index(["config_key"], unique=True)
        self.schemas["system_config"] = system_config
        
        # æŒ‰é’®é…ç½®è¡¨
        button_configs = TableSchema("button_configs")
        button_configs.add_field(SchemaField("id", "INTEGER", primary_key=True))
        button_configs.add_field(SchemaField("button_type", "VARCHAR(50)", nullable=False))
        button_configs.add_field(SchemaField("config_data", "TEXT"))
        button_configs.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        button_configs.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        self.schemas["button_configs"] = button_configs
        
        # è‡ªåŠ¨å›å¤è¡¨ - ä¿®å¤ç¼ºå¤±å­—æ®µ
        auto_reply_triggers = TableSchema("auto_reply_triggers")
        auto_reply_triggers.add_field(SchemaField("id", "INTEGER", primary_key=True))
        auto_reply_triggers.add_field(SchemaField("admin_id", "INTEGER", nullable=False))
        auto_reply_triggers.add_field(SchemaField("trigger_text", "TEXT", nullable=False))
        auto_reply_triggers.add_field(SchemaField("match_type", "VARCHAR(20)", default="contains"))
        auto_reply_triggers.add_field(SchemaField("created_by", "INTEGER", nullable=False))  # æ·»åŠ ç¼ºå¤±å­—æ®µ
        auto_reply_triggers.add_field(SchemaField("priority_order", "INTEGER", default="0"))
        auto_reply_triggers.add_field(SchemaField("is_active", "BOOLEAN", default="TRUE"))
        auto_reply_triggers.add_field(SchemaField("trigger_count", "INTEGER", default="0"))  # æ·»åŠ ç»Ÿè®¡å­—æ®µ
        auto_reply_triggers.add_field(SchemaField("last_triggered_at", "TIMESTAMP"))  # æ·»åŠ æœ€åè§¦å‘æ—¶é—´
        auto_reply_triggers.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        auto_reply_triggers.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        auto_reply_triggers.add_index(["admin_id"])
        auto_reply_triggers.add_index(["is_active"])
        auto_reply_triggers.add_index(["priority_order"])
        auto_reply_triggers.add_index(["created_by"])  # æ·»åŠ ç´¢å¼•
        self.schemas["auto_reply_triggers"] = auto_reply_triggers
        
        auto_reply_messages = TableSchema("auto_reply_messages")
        auto_reply_messages.add_field(SchemaField("id", "INTEGER", primary_key=True))
        auto_reply_messages.add_field(SchemaField("trigger_id", "INTEGER", nullable=False))
        auto_reply_messages.add_field(SchemaField("message_content", "TEXT", nullable=False))
        auto_reply_messages.add_field(SchemaField("display_order", "INTEGER", default="0"))
        auto_reply_messages.add_field(SchemaField("is_active", "BOOLEAN", default="TRUE"))
        auto_reply_messages.add_field(SchemaField("send_count", "INTEGER", default="0"))  # æ·»åŠ ç»Ÿè®¡å­—æ®µ
        auto_reply_messages.add_field(SchemaField("last_sent_at", "TIMESTAMP"))  # æ·»åŠ æœ€åå‘é€æ—¶é—´
        auto_reply_messages.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        auto_reply_messages.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))  # æ·»åŠ æ›´æ–°æ—¶é—´
        auto_reply_messages.foreign_keys.append("FOREIGN KEY (trigger_id) REFERENCES auto_reply_triggers(id) ON DELETE CASCADE")
        auto_reply_messages.add_index(["trigger_id"])
        auto_reply_messages.add_index(["display_order"])
        auto_reply_messages.add_index(["is_active"])
        self.schemas["auto_reply_messages"] = auto_reply_messages
        
        auto_reply_daily_stats = TableSchema("auto_reply_daily_stats")
        auto_reply_daily_stats.add_field(SchemaField("id", "INTEGER", primary_key=True))
        auto_reply_daily_stats.add_field(SchemaField("trigger_id", "INTEGER", nullable=False))
        auto_reply_daily_stats.add_field(SchemaField("stat_date", "DATE", nullable=False))
        auto_reply_daily_stats.add_field(SchemaField("trigger_count", "INTEGER", default="0"))
        auto_reply_daily_stats.add_field(SchemaField("unique_users", "INTEGER", default="0"))
        auto_reply_daily_stats.foreign_keys.append("FOREIGN KEY (trigger_id) REFERENCES auto_reply_triggers(id) ON DELETE CASCADE")
        auto_reply_daily_stats.add_index(["trigger_id", "stat_date"], unique=True)
        self.schemas["auto_reply_daily_stats"] = auto_reply_daily_stats
        
        # åœ°åŒºç®¡ç†è¡¨ï¼ˆå”¯ä¸€æ ‡å‡†ï¼šåŸå¸‚/åŒºå¿ï¼‰
        cities = TableSchema("cities")
        cities.add_field(SchemaField("id", "INTEGER", primary_key=True))
        cities.add_field(SchemaField("name", "VARCHAR(100)", nullable=False, unique=True))
        cities.add_field(SchemaField("code", "VARCHAR(10)", default="''"))
        cities.add_field(SchemaField("display_order", "INTEGER", default="0"))
        cities.add_field(SchemaField("is_active", "BOOLEAN", default="TRUE"))
        cities.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        cities.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        cities.add_index(["name"], unique=True)
        cities.add_index(["display_order"])
        cities.add_index(["is_active"])
        self.schemas["cities"] = cities
        
        districts = TableSchema("districts")
        districts.add_field(SchemaField("id", "INTEGER", primary_key=True))
        districts.add_field(SchemaField("city_id", "INTEGER", nullable=False))
        districts.add_field(SchemaField("name", "VARCHAR(100)", nullable=False))
        districts.add_field(SchemaField("code", "VARCHAR(10)", default="''"))
        districts.add_field(SchemaField("display_order", "INTEGER", default="0"))
        districts.add_field(SchemaField("is_active", "BOOLEAN", default="TRUE"))
        districts.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        districts.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        districts.foreign_keys.append("FOREIGN KEY (city_id) REFERENCES cities(id) ON DELETE CASCADE")
        districts.add_index(["city_id"])
        districts.add_index(["name"])
        districts.add_index(["display_order"])
        districts.add_index(["is_active"])
        self.schemas["districts"] = districts
        
        # å…³é”®è¯ç®¡ç†è¡¨
        keywords = TableSchema("keywords")
        keywords.add_field(SchemaField("id", "INTEGER", primary_key=True))
        keywords.add_field(SchemaField("name", "VARCHAR(255)", nullable=False, unique=True))  # ä¿®æ”¹ä¸ºnameå­—æ®µ
        keywords.add_field(SchemaField("display_order", "INTEGER", default="0"))
        keywords.add_field(SchemaField("is_active", "BOOLEAN", default="TRUE"))
        keywords.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        keywords.add_field(SchemaField("updated_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        keywords.add_index(["name"], unique=True)
        keywords.add_index(["display_order"])
        keywords.add_index(["is_active"])
        self.schemas["keywords"] = keywords
        
        merchant_keywords = TableSchema("merchant_keywords")
        merchant_keywords.add_field(SchemaField("id", "INTEGER", primary_key=True))
        merchant_keywords.add_field(SchemaField("merchant_id", "INTEGER", nullable=False))
        merchant_keywords.add_field(SchemaField("keyword_id", "INTEGER", nullable=False))
        merchant_keywords.add_field(SchemaField("created_at", "TIMESTAMP", default="CURRENT_TIMESTAMP"))
        merchant_keywords.foreign_keys.append("FOREIGN KEY (merchant_id) REFERENCES merchants(id) ON DELETE CASCADE")
        merchant_keywords.foreign_keys.append("FOREIGN KEY (keyword_id) REFERENCES keywords(id) ON DELETE CASCADE")
        merchant_keywords.add_index(["merchant_id"])
        merchant_keywords.add_index(["keyword_id"])
        merchant_keywords.add_index(["merchant_id", "keyword_id"], unique=True)
        self.schemas["merchant_keywords"] = merchant_keywords
    
    async def migrate_existing_tables(self) -> bool:
        """è¿ç§»ç°æœ‰è¡¨ï¼Œæ·»åŠ ç¼ºå¤±çš„å­—æ®µ"""
        try:
            logger.info("å¼€å§‹æ£€æŸ¥å¹¶è¿ç§»ç°æœ‰æ•°æ®åº“è¡¨...")
            from database.db_connection import db_manager
            
            # ç¡®ä¿ cities/districts å…·å¤‡å¿…è¦å­—æ®µ
            try:
                await db_manager.execute_query("SELECT display_order FROM cities LIMIT 1")
            except Exception:
                logger.info("ä¸ºcitiesè¡¨æ·»åŠ ç¼ºå¤±å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE cities ADD COLUMN display_order INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE cities ADD COLUMN is_active BOOLEAN DEFAULT TRUE") 
                await db_manager.execute_query("ALTER TABLE cities ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                logger.info("citiesè¡¨å­—æ®µè¿ç§»å®Œæˆ")
            
            try:
                await db_manager.execute_query("SELECT display_order FROM districts LIMIT 1")
            except Exception:
                logger.info("ä¸ºdistrictsè¡¨æ·»åŠ ç¼ºå¤±å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE districts ADD COLUMN display_order INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE districts ADD COLUMN is_active BOOLEAN DEFAULT TRUE")
                await db_manager.execute_query("ALTER TABLE districts ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                logger.info("districtsè¡¨å­—æ®µè¿ç§»å®Œæˆ")
            
            # æ£€æŸ¥keywordsè¡¨æ˜¯å¦éœ€è¦æ·»åŠ å­—æ®µï¼ˆåŒ…æ‹¬nameå­—æ®µï¼‰
            # é¦–å…ˆæ£€æŸ¥nameå­—æ®µ
            try:
                await db_manager.execute_query("SELECT name FROM keywords LIMIT 1")
            except Exception:
                logger.info("ä¸ºkeywordsè¡¨æ·»åŠ nameå­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE keywords ADD COLUMN name VARCHAR(255)")
                logger.info("keywordsè¡¨nameå­—æ®µæ·»åŠ å®Œæˆ")
                
            # ç„¶åæ£€æŸ¥å…¶ä»–å­—æ®µ
            try:
                await db_manager.execute_query("SELECT display_order FROM keywords LIMIT 1")
            except Exception:
                logger.info("ä¸ºkeywordsè¡¨æ·»åŠ å…¶ä»–ç¼ºå¤±å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE keywords ADD COLUMN display_order INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE keywords ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                logger.info("keywordsè¡¨å­—æ®µè¿ç§»å®Œæˆ")
            
            # æ£€æŸ¥auto_reply_triggersè¡¨æ˜¯å¦éœ€è¦æ·»åŠ å­—æ®µ
            # é¦–å…ˆæ£€æŸ¥created_byå­—æ®µ
            try:
                await db_manager.execute_query("SELECT created_by FROM auto_reply_triggers LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_triggersè¡¨æ·»åŠ created_byå­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_triggers ADD COLUMN created_by INTEGER DEFAULT 0")
                logger.info("auto_reply_triggersè¡¨created_byå­—æ®µæ·»åŠ å®Œæˆ")
            
            # æ£€æŸ¥å…¶ä»–ç¼ºå¤±å­—æ®µ
            try:
                await db_manager.execute_query("SELECT match_type FROM auto_reply_triggers LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_triggersè¡¨æ·»åŠ match_typeå­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_triggers ADD COLUMN match_type VARCHAR(20) DEFAULT 'contains'")
                logger.info("auto_reply_triggersè¡¨match_typeå­—æ®µæ·»åŠ å®Œæˆ")
            
            try:
                await db_manager.execute_query("SELECT priority_order FROM auto_reply_triggers LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_triggersè¡¨æ·»åŠ priority_orderå­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_triggers ADD COLUMN priority_order INTEGER DEFAULT 0")
                logger.info("auto_reply_triggersè¡¨priority_orderå­—æ®µæ·»åŠ å®Œæˆ")
            
            try:
                await db_manager.execute_query("SELECT trigger_count FROM auto_reply_triggers LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_triggersè¡¨æ·»åŠ ç»Ÿè®¡å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_triggers ADD COLUMN trigger_count INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE auto_reply_triggers ADD COLUMN last_triggered_at TIMESTAMP")
                logger.info("auto_reply_triggersè¡¨ç»Ÿè®¡å­—æ®µæ·»åŠ å®Œæˆ")
            
            # æ£€æŸ¥auto_reply_messagesè¡¨æ˜¯å¦éœ€è¦æ·»åŠ å­—æ®µ
            try:
                await db_manager.execute_query("SELECT display_order FROM auto_reply_messages LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_messagesè¡¨æ·»åŠ ç¼ºå¤±å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_messages ADD COLUMN display_order INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE auto_reply_messages ADD COLUMN is_active BOOLEAN DEFAULT TRUE")
                logger.info("auto_reply_messagesè¡¨å­—æ®µè¿ç§»å®Œæˆ")
            
            try:
                await db_manager.execute_query("SELECT send_count FROM auto_reply_messages LIMIT 1")
            except Exception:
                logger.info("ä¸ºauto_reply_messagesè¡¨æ·»åŠ ç»Ÿè®¡å­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE auto_reply_messages ADD COLUMN send_count INTEGER DEFAULT 0")
                await db_manager.execute_query("ALTER TABLE auto_reply_messages ADD COLUMN last_sent_at TIMESTAMP")
                await db_manager.execute_query("ALTER TABLE auto_reply_messages ADD COLUMN updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP")
                logger.info("auto_reply_messagesè¡¨ç»Ÿè®¡å­—æ®µæ·»åŠ å®Œæˆ")
            
            # æ£€æŸ¥ordersè¡¨æ˜¯å¦éœ€è¦æ·»åŠ order_typeå­—æ®µ
            try:
                await db_manager.execute_query("SELECT order_type FROM orders LIMIT 1")
            except Exception:
                logger.info("ä¸ºordersè¡¨æ·»åŠ order_typeå­—æ®µ...")
                await db_manager.execute_query("ALTER TABLE orders ADD COLUMN order_type VARCHAR(50)")
                logger.info("ordersè¡¨order_typeå­—æ®µæ·»åŠ å®Œæˆ")
            
            logger.info("æ•°æ®åº“è¡¨è¿ç§»æ£€æŸ¥å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¡¨è¿ç§»å¤±è´¥: {e}")
            return False

    async def _create_indexes_safely(self, table_name: str, indexes: List[str]) -> None:
        """å®‰å…¨åœ°åˆ›å»ºç´¢å¼•ï¼Œé¿å…é‡å¤åˆ›å»ºå·²å­˜åœ¨çš„ç´¢å¼•"""
        try:
            from database.db_connection import db_manager
            
            # è·å–ç°æœ‰ç´¢å¼•åˆ—è¡¨
            existing_indexes = await self._get_existing_indexes(table_name)
            
            for index_sql in indexes:
                try:
                    # ä»SQLä¸­æå–ç´¢å¼•å
                    index_name = self._extract_index_name(index_sql)
                    
                    if index_name in existing_indexes:
                        logger.debug(f"ç´¢å¼• {index_name} å·²å­˜åœ¨ï¼Œè·³è¿‡åˆ›å»º")
                        continue
                    
                    await db_manager.execute_query(index_sql)
                    logger.debug(f"ç´¢å¼• {index_name} åˆ›å»ºæˆåŠŸ")
                    
                except Exception as e:
                    # å¦‚æœæ˜¯ç´¢å¼•å·²å­˜åœ¨çš„é”™è¯¯ï¼Œè®°å½•ä¸ºdebugçº§åˆ«
                    if "already exists" in str(e).lower():
                        logger.debug(f"ç´¢å¼•å·²å­˜åœ¨ï¼Œè·³è¿‡: {index_sql}")
                    else:
                        logger.warning(f"åˆ›å»ºç´¢å¼•å¤±è´¥: {index_sql}, é”™è¯¯: {e}")
                        
        except Exception as e:
            logger.error(f"å®‰å…¨åˆ›å»ºç´¢å¼•å¤±è´¥: {e}")
    
    async def _get_existing_indexes(self, table_name: str) -> set:
        """è·å–è¡¨çš„ç°æœ‰ç´¢å¼•åˆ—è¡¨"""
        try:
            from database.db_connection import db_manager
            
            query = """
            SELECT name FROM sqlite_master 
            WHERE type = 'index' AND tbl_name = ?
            AND name NOT LIKE 'sqlite_%'
            """
            
            results = await db_manager.fetch_all(query, (table_name,))
            return {row[0] for row in results} if results else set()
            
        except Exception as e:
            logger.warning(f"è·å–ç°æœ‰ç´¢å¼•å¤±è´¥: {e}")
            return set()
    
    def _extract_index_name(self, index_sql: str) -> str:
        """ä»CREATE INDEX SQLè¯­å¥ä¸­æå–ç´¢å¼•å"""
        try:
            import re
            # åŒ¹é… CREATE [UNIQUE] INDEX index_name ON table_name
            match = re.search(r'CREATE\s+(?:UNIQUE\s+)?INDEX\s+(\w+)\s+ON', index_sql, re.IGNORECASE)
            if match:
                return match.group(1)
            return "unknown_index"
        except Exception:
            return "unknown_index"

    async def create_tables(self) -> bool:
        """åˆ›å»ºæ‰€æœ‰è¡¨"""
        try:
            logger.info("å¼€å§‹åˆ›å»ºæ•°æ®åº“è¡¨...")
            
            # é¦–å…ˆè¿›è¡Œç°æœ‰è¡¨çš„è¿ç§»
            await self.migrate_existing_tables()
            
            # æŒ‰ä¾èµ–é¡ºåºåˆ›å»ºè¡¨
            table_order = [
                "provinces", "regions", "merchants", "orders", "binding_codes",
                "activity_logs", "fsm_states", "system_config", "button_configs",
                "auto_reply_triggers", "auto_reply_messages", "auto_reply_daily_stats",
                "keywords", "merchant_keywords"
            ]
            
            created_count = 0
            for table_name in table_order:
                if table_name in self.schemas:
                    schema = self.schemas[table_name]
                    sql = schema.to_sql()
                    
                    if sql:
                        logger.debug(f"åˆ›å»ºè¡¨ {table_name}: {sql}")
                        await db_manager.execute_query(sql)
                        
                        # åˆ›å»ºç´¢å¼• - æ·»åŠ å­˜åœ¨æ€§æ£€æŸ¥
                        await self._create_indexes_safely(table_name, schema.indexes)
                        
                        created_count += 1
                        logger.info(f"âœ… è¡¨ {table_name} åˆ›å»ºæˆåŠŸ")
            
            # åˆ›å»ºè¿ç§»å†å²è¡¨
            migration_sql = """
            CREATE TABLE IF NOT EXISTS migration_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                migration_name TEXT UNIQUE NOT NULL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
            """
            await db_manager.execute_query(migration_sql)
            
            logger.info(f"æ•°æ®åº“è¡¨åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {created_count} ä¸ªè¡¨")
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“è¡¨å¤±è´¥: {e}")
            return False
    
    async def get_table_info(self, table_name: str) -> Optional[Dict]:
        """è·å–è¡¨ä¿¡æ¯"""
        try:
            result = await db_manager.fetch_all(f"PRAGMA table_info({table_name})")
            if result:
                return {
                    "columns": [{"name": row[1], "type": row[2], "nullable": not row[3]} for row in result]
                }
        except Exception as e:
            logger.debug(f"è·å–è¡¨ {table_name} ä¿¡æ¯å¤±è´¥: {e}")
        return None

# å…¨å±€å®ä¾‹
auto_schema_manager = AutoSchemaManager()

async def auto_initialize_database() -> bool:
    """è‡ªåŠ¨åˆå§‹åŒ–æ•°æ®åº“"""
    try:
        logger.info("ğŸ”„ ä½¿ç”¨è‡ªåŠ¨æ¶æ„ç®¡ç†å™¨åˆå§‹åŒ–æ•°æ®åº“...")
        
        # åˆ†æä»£ç åº“
        await auto_schema_manager.analyze_codebase()
        
        # åˆ›å»ºè¡¨
        success = await auto_schema_manager.create_tables()
        
        if success:
            logger.info("âœ… è‡ªåŠ¨æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
        else:
            logger.error("âŒ è‡ªåŠ¨æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
        
        return success
        
    except Exception as e:
        logger.error(f"è‡ªåŠ¨æ•°æ®åº“åˆå§‹åŒ–è¿‡ç¨‹å¤±è´¥: {e}")
        return False
