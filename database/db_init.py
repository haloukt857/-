"""
æ•°æ®åº“åˆå§‹åŒ–æ¨¡å—
è´Ÿè´£åˆ›å»ºæ•°æ®åº“è¡¨ç»“æ„ã€æ‰§è¡Œè¿ç§»å’Œåˆå§‹åŒ–ç³»ç»Ÿé…ç½®
"""

import os
import logging
import glob
import re
from typing import Dict, List, Optional, Tuple
import json
from datetime import datetime, timedelta

# å¯¼å…¥æ•°æ®åº“è¿æ¥ç®¡ç†å™¨
from .db_connection import db_manager
from .schema_sync import schema_sync

# å¯¼å…¥è·¯å¾„ç®¡ç†å™¨
from pathmanager import PathManager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class DatabaseInitializer:
    """æ•°æ®åº“åˆå§‹åŒ–å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ•°æ®åº“åˆå§‹åŒ–å™¨"""
        self.current_schema_version = "2025.09.28.1"
        self.migrations_dir = PathManager.get_database_migration_path()
        self.migration_history = []
    
    async def initialize_database(self) -> bool:
        """
        æ™ºèƒ½æ•°æ®åº“åˆå§‹åŒ– - æ”¯æŒå…¨æ–°åˆ›å»ºå’Œå¢é‡è¿ç§»
        
        Returns:
            åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
            
            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨ä»¥åŠå½“å‰ç‰ˆæœ¬
            current_version = await self.get_schema_version()
            is_fresh_install = current_version is None
            
            if is_fresh_install:
                logger.info("æ£€æµ‹åˆ°æ–°æ•°æ®åº“ï¼Œæ‰§è¡Œå®Œæ•´åˆå§‹åŒ–...")
                success = await self._fresh_install()
            else:
                logger.info(f"æ£€æµ‹åˆ°ç°æœ‰æ•°æ®åº“ï¼Œç‰ˆæœ¬: {current_version}")
                if current_version != self.current_schema_version:
                    logger.info(f"éœ€è¦è¿ç§»åˆ°ç‰ˆæœ¬: {self.current_schema_version}")
                    success = await self._migrate_database(current_version, self.current_schema_version)
                else:
                    logger.info("æ•°æ®åº“ç‰ˆæœ¬å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€è¿ç§»")
                    success = await self._verify_tables()
                    if not success:
                        logger.warning("æ£€æµ‹åˆ°è¡¨ç¼ºå¤±æˆ–ç»“æ„ä¸å®Œæ•´ï¼Œå°è¯•æ‰§è¡ŒSchemaè‡ªä¿®å¤...")
                        # é¦–é€‰ï¼šé‡æ–°æ‰§è¡Œschema.sqlï¼ˆå¼€å‘é˜¶æ®µçš„ç¨³å¦¥è‡ªä¿®å¤ï¼‰
                        try:
                            await self._auto_generate_migration(current_version, self.current_schema_version)
                        except Exception as e:
                            logger.warning(f"è‡ªåŠ¨è¿ç§»æ‰§è¡Œå¼‚å¸¸: {e}")
                        # å…¶æ¬¡ï¼šæ‰§è¡Œç»“æ„åŒæ­¥ï¼ˆå­—æ®µ/ç´¢å¼•ç­‰ï¼‰
                        try:
                            _ = await schema_sync.synchronize_schema()
                        except Exception as e:
                            logger.warning(f"SchemaåŒæ­¥å¼‚å¸¸: {e}")
                        # è¡¥é½å·²çŸ¥ç¼ºå¤±æ¨¡å—ï¼ˆè‡ªåŠ¨å›å¤/å…³é”®è¯ï¼‰
                        try:
                            await self._ensure_auto_reply_and_keywords_tables()
                        except Exception as e:
                            logger.warning(f"è¡¥é½è‡ªåŠ¨å›å¤/å…³é”®è¯è¡¨å¼‚å¸¸: {e}")
                        # å†æ¬¡éªŒè¯
                        success = await self._verify_tables()
            
            if success:
                # ç¡®ä¿å…³é”®æ¨¡æ¿å­˜åœ¨ + è¡¥é½æ‰€æœ‰å…³é”®é”®
                await self._ensure_critical_templates()
                await self._verify_critical_templates()
                logger.info(f"æ•°æ®åº“å°±ç»ªï¼Œå½“å‰ç‰ˆæœ¬: {self.current_schema_version}")
                return True
            else:
                logger.error("æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def _verify_tables(self) -> bool:
        """
        éªŒè¯æ‰€æœ‰å¿…éœ€çš„è¡¨æ˜¯å¦å­˜åœ¨
        
        Returns:
            æ‰€æœ‰è¡¨æ˜¯å¦éƒ½å­˜åœ¨
        """
        required_tables = [
            'merchants', 'orders', 'binding_codes', 'button_configs',
            'activity_logs', 'fsm_states', 'system_config',
            'auto_reply_triggers', 'auto_reply_messages', 'auto_reply_daily_stats',
            'cities', 'districts', 'keywords', 'merchant_keywords',
            'posting_time_slots', 'posting_channels'
        ]
        
        try:
            for table in required_tables:
                result = await db_manager.fetch_one(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
                    (table,)
                )
                
                if not result:
                    logger.error(f"è¡¨ {table} ä¸å­˜åœ¨")
                    return False
                    
                logger.debug(f"è¡¨ {table} éªŒè¯æˆåŠŸ")
            
            logger.info("æ‰€æœ‰æ•°æ®åº“è¡¨éªŒè¯æˆåŠŸ")
            return True
            
        except Exception as e:
            logger.error(f"è¡¨éªŒè¯å¤±è´¥: {e}")
            return False
    
    async def _execute_sql_script(self, sql_script: str):
        """æ‰§è¡ŒSQLè„šæœ¬ - ä½¿ç”¨SQLiteåŸç”Ÿexecutescriptæ–¹æ³•"""
        try:
            # æ¸…ç†SQLè„šæœ¬ï¼šåªç§»é™¤æ³¨é‡Šï¼Œä¿æŒç»“æ„å®Œæ•´
            clean_lines = []
            for line in sql_script.split('\n'):
                # ç§»é™¤è¡Œå†…æ³¨é‡Šä½†ä¿æŒè¡Œç»“æ„
                if '--' in line:
                    line = line[:line.index('--')]
                line = line.rstrip()
                if line:  # ä¿ç•™ç©ºè¡Œä»¥ç»´æŒè¯­å¥ç»“æ„
                    clean_lines.append(line)
            
            clean_sql = '\n'.join(clean_lines)
            
            # ä½¿ç”¨SQLiteçš„executescriptæ–¹æ³•æ‰§è¡Œå¤šè¯­å¥è„šæœ¬
            async with db_manager.get_connection() as conn:
                await conn.executescript(clean_sql)
                await conn.commit()
            
            logger.info("âœ… SQLè„šæœ¬æ‰§è¡Œå®Œæˆ")
            
        except Exception as e:
            logger.error(f"SQLè„šæœ¬æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def _ensure_auto_reply_and_keywords_tables(self):
        """æ˜¾å¼è¡¥é½è‡ªåŠ¨å›å¤ä¸å…³é”®è¯ç›¸å…³è¡¨ï¼ˆå®¹é”™ä¿®å¤ï¼‰ã€‚"""
        ddl = """
        CREATE TABLE IF NOT EXISTS auto_reply_triggers (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            admin_id INTEGER,
            trigger_text TEXT NOT NULL,
            match_type TEXT NOT NULL CHECK (match_type IN ('exact','contains')),
            is_active BOOLEAN DEFAULT TRUE,
            priority_order INTEGER DEFAULT 0,
            trigger_count INTEGER DEFAULT 0,
            last_triggered_at TIMESTAMP,
            created_by INTEGER,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(trigger_text, match_type)
        );
        CREATE TABLE IF NOT EXISTS auto_reply_messages (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            trigger_id INTEGER NOT NULL,
            message_content TEXT NOT NULL,
            is_active BOOLEAN DEFAULT TRUE,
            display_order INTEGER DEFAULT 0,
            send_count INTEGER DEFAULT 0,
            last_sent_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (trigger_id) REFERENCES auto_reply_triggers(id) ON DELETE CASCADE
        );
        CREATE TABLE IF NOT EXISTS auto_reply_daily_stats (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            trigger_id INTEGER NOT NULL,
            stat_date DATE NOT NULL,
            trigger_count INTEGER DEFAULT 0,
            unique_users_count INTEGER DEFAULT 0,
            total_messages_sent INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (trigger_id) REFERENCES auto_reply_triggers(id) ON DELETE CASCADE,
            UNIQUE(trigger_id, stat_date)
        );
        CREATE TABLE IF NOT EXISTS keywords (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL UNIQUE,
            display_order INTEGER DEFAULT 0,
            is_active BOOLEAN DEFAULT TRUE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        CREATE TABLE IF NOT EXISTS merchant_keywords (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            merchant_id INTEGER NOT NULL,
            keyword_id INTEGER NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            UNIQUE(merchant_id, keyword_id),
            FOREIGN KEY (merchant_id) REFERENCES merchants(id) ON DELETE CASCADE,
            FOREIGN KEY (keyword_id) REFERENCES keywords(id) ON DELETE CASCADE
        );
        CREATE INDEX IF NOT EXISTS idx_auto_triggers_active ON auto_reply_triggers(is_active);
        CREATE INDEX IF NOT EXISTS idx_auto_triggers_text ON auto_reply_triggers(trigger_text);
        CREATE INDEX IF NOT EXISTS idx_auto_msgs_trigger ON auto_reply_messages(trigger_id);
        CREATE INDEX IF NOT EXISTS idx_auto_stats_date ON auto_reply_daily_stats(stat_date);
        -- å›ºå®šå‘é€æ—¶é—´æ§½ä½é…ç½®
        CREATE TABLE IF NOT EXISTS posting_time_slots (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            time_str TEXT NOT NULL,              -- æ ¼å¼ HH:MM
            is_active BOOLEAN DEFAULT 1,
            display_order INTEGER DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        -- å‘å¸ƒé¢‘é“é…ç½®ï¼ˆæ”¯æŒå¤šæ¡ï¼Œç½®é¡¶ä¸€æ¡ä¸ºå½“å‰ä½¿ç”¨ï¼‰
        CREATE TABLE IF NOT EXISTS posting_channels (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            display_name TEXT,
            channel_chat_id TEXT,      -- å¦‚ -100xxxx æˆ– @username
            channel_link TEXT,         -- https://t.me/xxx
            is_active BOOLEAN DEFAULT 1,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        );
        """
        await self._execute_sql_script(ddl)

        # adv_sentence å­—æ®µç”± schema.sqlï¼ˆå…¨æ–°å®‰è£…ï¼‰æˆ– migrations ç»Ÿä¸€ç®¡ç†ï¼Œä¸åœ¨æ­¤å¤„é‡å¤å…œåº•

    async def _log_initialization(self):
        """è®°å½•åˆå§‹åŒ–æ—¥å¿—"""
        try:
            await db_manager.execute_query(
                """INSERT INTO activity_logs (user_id, action_type, details, timestamp) 
                   VALUES (?, ?, ?, ?)""",
                (
                    0,  # ç³»ç»Ÿç”¨æˆ·ID
                    'system_init',
                    json.dumps({
                        'action': 'database_initialized',
                        'schema_version': self.current_schema_version,
                        'timestamp': datetime.now().isoformat()
                    }, ensure_ascii=False),
                    datetime.now()
                )
            )
            logger.info("æ•°æ®åº“åˆå§‹åŒ–æ—¥å¿—è®°å½•å®Œæˆ")
        except Exception as e:
            logger.warning(f"è®°å½•åˆå§‹åŒ–æ—¥å¿—å¤±è´¥: {e}")
    
    async def get_schema_version(self) -> Optional[str]:
        """
        è·å–å½“å‰æ•°æ®åº“æ¶æ„ç‰ˆæœ¬
        
        Returns:
            æ¶æ„ç‰ˆæœ¬å­—ç¬¦ä¸²
        """
        try:
            result = await db_manager.fetch_one(
                "SELECT config_value FROM system_config WHERE config_key = ?",
                ('schema_version',)
            )
            return result[0] if result else None
        except Exception as e:
            logger.error(f"è·å–æ¶æ„ç‰ˆæœ¬å¤±è´¥: {e}")
            return None
    
    async def update_schema_version(self, version: str) -> bool:
        """
        æ›´æ–°æ•°æ®åº“æ¶æ„ç‰ˆæœ¬
        
        Args:
            version: æ–°çš„ç‰ˆæœ¬å·
            
        Returns:
            æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        try:
            await db_manager.execute_query(
                """INSERT OR REPLACE INTO system_config (config_key, config_value, description) 
                   VALUES (?, ?, ?)""",
                ('schema_version', version, 'æ•°æ®åº“æ¶æ„ç‰ˆæœ¬')
            )
            logger.info(f"æ¶æ„ç‰ˆæœ¬æ›´æ–°ä¸º: {version}")
            return True
        except Exception as e:
            logger.error(f"æ›´æ–°æ¶æ„ç‰ˆæœ¬å¤±è´¥: {e}")
            return False
    
    async def run_migration(self, migration_name: str, migration_sql: str) -> bool:
        """
        æ‰§è¡Œæ•°æ®åº“è¿ç§»
        
        Args:
            migration_name: è¿ç§»åç§°
            migration_sql: è¿ç§»SQLè¯­å¥
            
        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info(f"å¼€å§‹æ‰§è¡Œè¿ç§»: {migration_name}")
            
            # æ£€æŸ¥è¿ç§»æ˜¯å¦å·²ç»æ‰§è¡Œè¿‡
            if await self._is_migration_applied(migration_name):
                logger.info(f"è¿ç§» {migration_name} å·²ç»æ‰§è¡Œè¿‡ï¼Œè·³è¿‡")
                return True
            
            # æ ¹æ®å†…å®¹é€‰æ‹©æ‰§è¡Œç­–ç•¥ï¼šåŒ…å«äº‹åŠ¡/è§¦å‘å™¨çš„è¿ç§»ä½¿ç”¨ executescriptï¼Œé¿å…åˆ†å·æ‹†åˆ†å¯¼è‡´çš„è¯­æ³•ä¸å®Œæ•´
            lower_sql = migration_sql.lower()
            contains_complex = any(k in lower_sql for k in [
                'create trigger', 'begin transaction', 'commit', 'pragma foreign_keys'
            ])

            success_count = 0
            error_count = 0

            if contains_complex:
                try:
                    await self._execute_sql_script(migration_sql)
                    success_count = 1
                    sql_statements = [migration_sql]
                except Exception as stmt_error:
                    logger.error(f"æ•´è„šæœ¬æ‰§è¡Œå¤±è´¥: {stmt_error}")
                    sql_statements = [migration_sql]
                    error_count = 1
            else:
                sql_statements = [stmt.strip() for stmt in migration_sql.split(';') if stmt.strip()]
                for statement in sql_statements:
                    if statement:
                        try:
                            await db_manager.execute_query(statement)
                            success_count += 1
                            logger.debug(f"SQLè¯­å¥æ‰§è¡ŒæˆåŠŸ: {statement[:50]}...")
                        except Exception as stmt_error:
                            error_msg = str(stmt_error).lower()
                            # SQLiteå®¹é”™å¤„ç†ï¼šå¿½ç•¥å¯é¢„æœŸçš„é”™è¯¯
                            if any(ignore_phrase in error_msg for ignore_phrase in [
                                'duplicate column name',  # åˆ—å·²å­˜åœ¨
                                'table already exists',   # è¡¨å·²å­˜åœ¨
                                'index already exists',   # ç´¢å¼•å·²å­˜åœ¨
                            ]):
                                logger.warning(f"å¿½ç•¥é¢„æœŸé”™è¯¯: {stmt_error}")
                                logger.info(f"SQLè¯­å¥è·³è¿‡ï¼ˆç»“æ„å·²å­˜åœ¨ï¼‰: {statement[:50]}...")
                                success_count += 1
                            else:
                                logger.error(f"SQLè¯­å¥æ‰§è¡Œå¤±è´¥: {statement[:50]}... | é”™è¯¯: {stmt_error}")
                                error_count += 1
            
            # åˆ¤æ–­è¿ç§»æˆåŠŸæ¡ä»¶ï¼šè‡³å°‘æœ‰ä¸€æ¡è¯­å¥æˆåŠŸï¼Œæˆ–è€…æ‰€æœ‰é”™è¯¯éƒ½æ˜¯å¯å¿½ç•¥çš„
            if success_count > 0 or error_count == 0:
                # è®°å½•è¿ç§»å†å²
                await self._record_migration(migration_name)
                logger.info(f"âœ… è¿ç§» {migration_name} æ‰§è¡ŒæˆåŠŸ (æˆåŠŸ:{success_count}, è·³è¿‡:{len(sql_statements)-success_count-error_count}, é”™è¯¯:{error_count})")
                return True
            else:
                logger.error(f"âŒ è¿ç§» {migration_name} æ‰§è¡Œå¤±è´¥ï¼Œæ‰€æœ‰è¯­å¥éƒ½å¤±è´¥äº†")
                return False
            
        except Exception as e:
            logger.error(f"è¿ç§» {migration_name} æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    async def _is_migration_applied(self, migration_name: str) -> bool:
        """æ£€æŸ¥è¿ç§»æ˜¯å¦å·²ç»åº”ç”¨"""
        try:
            # é¦–å…ˆç¡®ä¿è¿ç§»å†å²è¡¨å­˜åœ¨
            await db_manager.execute_query("""
                CREATE TABLE IF NOT EXISTS migration_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    migration_name TEXT UNIQUE NOT NULL,
                    applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            result = await db_manager.fetch_one(
                "SELECT migration_name FROM migration_history WHERE migration_name = ?",
                (migration_name,)
            )
            return result is not None
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¿ç§»çŠ¶æ€å¤±è´¥: {e}")
            return False
    
    async def _record_migration(self, migration_name: str):
        """è®°å½•è¿ç§»å†å²"""
        try:
            await db_manager.execute_query(
                "INSERT INTO migration_history (migration_name) VALUES (?)",
                (migration_name,)
            )
        except Exception as e:
            logger.error(f"è®°å½•è¿ç§»å†å²å¤±è´¥: {e}")
    
    async def cleanup_expired_data(self):
        """æ¸…ç†è¿‡æœŸæ•°æ®"""
        try:
            logger.info("å¼€å§‹æ¸…ç†è¿‡æœŸæ•°æ®...")
            
            # æ¸…ç†è¿‡æœŸçš„ç»‘å®šç 
            expired_time = datetime.now() - timedelta(hours=24)
            result = await db_manager.execute_query(
                "DELETE FROM binding_codes WHERE expires_at < ? AND is_used = FALSE",
                (expired_time,)
            )
            logger.info(f"æ¸…ç†äº† {result} ä¸ªè¿‡æœŸç»‘å®šç ")
            
            # æ¸…ç†æ—§çš„æ´»åŠ¨æ—¥å¿—ï¼ˆä¿ç•™30å¤©ï¼‰
            old_log_time = datetime.now() - timedelta(days=30)
            result = await db_manager.execute_query(
                "DELETE FROM activity_logs WHERE timestamp < ?",
                (old_log_time,)
            )
            logger.info(f"æ¸…ç†äº† {result} æ¡æ—§æ´»åŠ¨æ—¥å¿—")
            
            # æ¸…ç†æ—§çš„FSMçŠ¶æ€ï¼ˆä¿ç•™7å¤©ï¼‰
            old_state_time = datetime.now() - timedelta(days=7)
            result = await db_manager.execute_query(
                "DELETE FROM fsm_states WHERE updated_at < ?",
                (old_state_time,)
            )
            logger.info(f"æ¸…ç†äº† {result} ä¸ªæ—§FSMçŠ¶æ€")
            
            # æ¸…ç†æ—§çš„è‡ªåŠ¨å›å¤æ¯æ—¥ç»Ÿè®¡ï¼ˆä¿ç•™90å¤©ï¼‰
            old_stats_time = datetime.now() - timedelta(days=90)
            result = await db_manager.execute_query(
                "DELETE FROM auto_reply_daily_stats WHERE stat_date < ?",
                (old_stats_time.date(),)
            )
            logger.info(f"æ¸…ç†äº† {result} æ¡æ—§è‡ªåŠ¨å›å¤ç»Ÿè®¡")
            
            logger.info("è¿‡æœŸæ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")

    async def _fresh_install(self) -> bool:
        """
        å…¨æ–°æ•°æ®åº“å®‰è£…
        
        Returns:
            å®‰è£…æ˜¯å¦æˆåŠŸ
        """
        logger.info("æ‰§è¡Œå…¨æ–°æ•°æ®åº“å®‰è£…...")
        
        try:
            # è‹¥æ•°æ®åº“æ–‡ä»¶å·²å­˜åœ¨ä½†æ— ç‰ˆæœ¬ä¿¡æ¯ï¼Œè§†ä¸ºâ€œè„æ–°åº“â€ï¼Œå…ˆåšç¡¬é‡ç½®
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰ä»»æ„ç”¨æˆ·è¡¨ï¼ˆæ’é™¤ sqlite å†…ç½®å’Œä¸´æ—¶è¡¨ï¼‰
                existing_tables = await db_manager.fetch_all(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'"
                )
            except Exception:
                existing_tables = []

            if existing_tables:
                logger.warning("æ£€æµ‹åˆ°æ— ç‰ˆæœ¬ä½†å­˜åœ¨æ—§è¡¨çš„æ•°æ®åº“ï¼Œæ‰§è¡Œç¡¬é‡ç½®ä»¥ç¡®ä¿å…¨æ–°æ¶æ„â€¦")
                try:
                    # å…³é—­è¿æ¥æ± ï¼Œåˆ é™¤æ•°æ®åº“æ–‡ä»¶åŠå…¶ WAL/SHM
                    await db_manager.close_all_connections()
                    db_path = db_manager.db_path
                    wal_path = f"{db_path}-wal"
                    shm_path = f"{db_path}-shm"
                    for p in (db_path, wal_path, shm_path):
                        try:
                            if os.path.exists(p):
                                os.remove(p)
                                logger.info(f"å·²åˆ é™¤æ•°æ®åº“ç›¸å…³æ–‡ä»¶: {p}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {p}: {e}")
                except Exception as e:
                    logger.warning(f"ç¡¬é‡ç½®æ•°æ®åº“æ—¶å‡ºç°é—®é¢˜(å¯å¿½ç•¥): {e}")

            # è¯»å–å¹¶æ‰§è¡Œä¸»è¦æ¶æ„SQL
            schema_path = PathManager.get_database_schema_path()
            
            if not os.path.exists(schema_path):
                logger.error(f"æ¶æ„æ–‡ä»¶ä¸å­˜åœ¨: {schema_path}")
                return False
            
            with open(schema_path, 'r', encoding='utf-8') as f:
                schema_sql = f.read()
            
            # æ‰§è¡Œä¸»æ¶æ„åˆ›å»º
            await self._execute_sql_script(schema_sql)
            
            # è·³è¿‡æ‰©å±•æ¶æ„æ‰§è¡Œ - V2.0è¿ç§»è„šæœ¬å·²åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µå’Œè¡¨
            logger.info("V2.0æ¶æ„ï¼šè·³è¿‡æ‰©å±•æ¶æ„æ‰§è¡Œï¼Œæ‰€æœ‰å­—æ®µå·²åœ¨ä¸»æ¶æ„ä¸­åŒ…å«")
            
            # ç¡®ä¿æ‰€æœ‰å¿…éœ€è¡¨éƒ½å­˜åœ¨ï¼ˆåŒ…æ‹¬posting_time_slotsç­‰ï¼‰
            await self._ensure_auto_reply_and_keywords_tables()
            
            # adv_sentence å­—æ®µç”± schema.sqlï¼ˆå…¨æ–°å®‰è£…ï¼‰æˆ– migrations ç»Ÿä¸€ç®¡ç†ï¼Œä¸åœ¨æ­¤å¤„é‡å¤å…œåº•
            
            # æ‰§è¡Œè‡ªåŠ¨å›å¤æ¶æ„
            auto_reply_schema_path = PathManager.get_database_schema_path('schema_auto_reply.sql')
            if os.path.exists(auto_reply_schema_path):
                logger.info("æ‰§è¡Œè‡ªåŠ¨å›å¤åŠŸèƒ½æ¶æ„...")
                with open(auto_reply_schema_path, 'r', encoding='utf-8') as f:
                    auto_reply_sql = f.read()
                await self._execute_sql_script(auto_reply_sql)
                logger.info("è‡ªåŠ¨å›å¤åŠŸèƒ½æ¶æ„æ‰§è¡Œå®Œæˆ")
            else:
                logger.warning("è‡ªåŠ¨å›å¤æ¶æ„æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡è‡ªåŠ¨å›å¤åŠŸèƒ½åˆå§‹åŒ–")
            
            # æ‰§è¡Œè‡³æœ€æ–°ç‰ˆæœ¬çš„è¿ç§»ï¼ˆç¡®ä¿ fresh install ä¹ŸåŒ…å«å¢é‡ç»“æ„ï¼Œå¦‚è¯„ä»·V2è¡¨ï¼‰
            try:
                _ = await self._migrate_database("0.0.0.0", self.current_schema_version)
            except Exception as e:
                logger.warning(f"fresh install è¿ç§»æ‰§è¡Œå¼‚å¸¸ï¼ˆå°†ç›´æ¥è®¾ç½®ç‰ˆæœ¬å·ï¼‰ï¼š{e}")
                await self.update_schema_version(self.current_schema_version)
            
            # æ‰§è¡Œæ¨¡æ¿æ•°æ®åˆå§‹åŒ–
            logger.info("ğŸ“„ æ‰§è¡Œæ¨¡æ¿æ•°æ®åˆå§‹åŒ–...")
            templates_init_success = await self._initialize_templates()
            
            if not templates_init_success:
                logger.warning("æ¨¡æ¿æ•°æ®åˆå§‹åŒ–å‡ºç°é—®é¢˜ï¼Œä½†ç»§ç»­åç»­æµç¨‹")
            
            # æ‰§è¡ŒSchemaç»“æ„åŒæ­¥æ£€æŸ¥ï¼ˆç¡®ä¿æ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨ï¼‰
            logger.info("ğŸ”„ æ‰§è¡ŒSchemaç»“æ„åŒæ­¥æ£€æŸ¥...")
            schema_sync_success = await schema_sync.synchronize_schema()
            
            if not schema_sync_success:
                logger.warning("SchemaåŒæ­¥å‡ºç°é—®é¢˜ï¼Œä½†ç»§ç»­éªŒè¯è¡¨ç»“æ„")
            
            # éªŒè¯å®‰è£…
            if await self._verify_tables():
                logger.info("âœ… å…¨æ–°å®‰è£…å®Œæˆ")
                await self._log_initialization()
                return True
            else:
                logger.error("å®‰è£…åè¡¨éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"å…¨æ–°å®‰è£…å¤±è´¥: {e}")
            return False

    async def _get_table_columns(self, table_name: str) -> set:
        """è·å–æŒ‡å®šè¡¨çš„æ‰€æœ‰åˆ—åé›†åˆã€‚"""
        try:
            rows = await db_manager.fetch_all(f"PRAGMA table_info({table_name})")
            return {row['name'] for row in rows} if rows else set()
        except Exception:
            return set()

    async def _filter_extended_sql(self, raw_sql: str) -> str:
        """
        è¿‡æ»¤æ‰©å±•SQLä¸­çš„é‡å¤ ADD COLUMN è¯­å¥ï¼Œé¿å… fresh install æ—¶é‡å¤æ·»åŠ åˆ—ã€‚

        ä»…é’ˆå¯¹ä»¥ä¸‹è¯­å¥åšå»é‡ï¼š
        - ALTER TABLE merchants ADD COLUMN ...
        - ALTER TABLE cities ADD COLUMN code ...
        å…¶ä»– CREATE TABLE/INDEX/TRIGGER è¯­å¥åŸæ ·ä¿ç•™ã€‚
        """
        import re
        merchants_cols = await self._get_table_columns('merchants')
        cities_cols = await self._get_table_columns('cities')

        filtered_lines = []
        for line in raw_sql.splitlines():
            line_strip = line.strip()
            m = re.match(r"(?i)ALTER\s+TABLE\s+merchants\s+ADD\s+COLUMN\s+([a-zA-Z_][a-zA-Z0-9_]*)\b", line_strip)
            if m:
                col = m.group(1)
                if col in merchants_cols:
                    continue  # è·³è¿‡å·²å­˜åœ¨çš„åˆ—
            m2 = re.match(r"(?i)ALTER\s+TABLE\s+cities\s+ADD\s+COLUMN\s+([a-zA-Z_][a-zA-Z0-9_]*)\b", line_strip)
            if m2:
                col2 = m2.group(1)
                if col2 in cities_cols:
                    continue
            filtered_lines.append(line)
        return "\n".join(filtered_lines)

    async def _migrate_database(self, from_version: str, to_version: str) -> bool:
        """
        æ‰§è¡Œæ•°æ®åº“è¿ç§»
        
        Args:
            from_version: æºç‰ˆæœ¬
            to_version: ç›®æ ‡ç‰ˆæœ¬
            
        Returns:
            è¿ç§»æ˜¯å¦æˆåŠŸ
        """
        logger.info(f"å¼€å§‹è¿ç§»: {from_version} -> {to_version}")
        
        try:
            # è·å–éœ€è¦æ‰§è¡Œçš„è¿ç§»æ–‡ä»¶
            migration_files = self._get_migration_files(from_version, to_version)
            
            if not migration_files:
                logger.info("æœªæ‰¾åˆ°éœ€è¦æ‰§è¡Œçš„è¿ç§»æ–‡ä»¶ï¼Œæ‰§è¡Œè‡ªåŠ¨è¿ç§»")
                # å¼€å‘é˜¶æ®µï¼šç›´æ¥æ›´æ–°åˆ°æœ€æ–°ç‰ˆæœ¬
                await self._auto_generate_migration(from_version, to_version)
                return True
            
            # æŒ‰ç‰ˆæœ¬é¡ºåºæ‰§è¡Œè¿ç§»
            for migration_file in sorted(migration_files):
                logger.info(f"æ‰§è¡Œè¿ç§»: {migration_file}")
                
                migration_path = PathManager.get_database_migration_file_path(migration_file)
                with open(migration_path, 'r', encoding='utf-8') as f:
                    migration_sql = f.read()
                
                # æ¡ä»¶è·³è¿‡ï¼š2025-09-16-2 åŸå¸‚åŒºå¿åˆ‡æ¢åœ¨æ–°åº“ï¼ˆå·²æ— æ—§è¡¨/æ—§åˆ—ï¼‰ä¸Šæ— éœ€æ‰§è¡Œ
                try:
                    if '2025_09_16_2_åˆ‡æ¢ä¸ºåŸå¸‚åŒºå¿å¹¶é‡å‘½åå¤–é”®' in migration_file:
                        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ—§ç»“æ„
                        has_old_cols = False
                        try:
                            cols = await db_manager.fetch_all("PRAGMA table_info(merchants)")
                            names = [c[1] if isinstance(c, tuple) else c['name'] for c in cols]
                            if 'province_id' in names or 'region_id' in names:
                                has_old_cols = True
                        except Exception:
                            pass
                        # æ£€æŸ¥æ—§è¡¨
                        async def table_exists(name: str) -> bool:
                            try:
                                row = await db_manager.fetch_one("SELECT name FROM sqlite_master WHERE type='table' AND name=?", (name,))
                                return bool(row)
                            except Exception:
                                return False
                        if not has_old_cols and not (await table_exists('provinces')) and not (await table_exists('regions')):
                            logger.info("è·³è¿‡è¿ç§» 2025_09_16_2ï¼šæœªæ£€æµ‹åˆ°æ—§è¡¨/æ—§åˆ—ï¼ˆå·²æ˜¯æ–°ç»“æ„ï¼‰")
                            await self._record_migration(migration_file)
                            continue
                except Exception as e:
                    logger.warning(f"è¿ç§»å‰ç½®æ£€æŸ¥å¼‚å¸¸ï¼ˆç»§ç»­å°è¯•æ‰§è¡Œï¼‰: {e}")

                # æ‰§è¡Œè¿ç§»
                success = await self.run_migration(migration_file, migration_sql)
                if not success:
                    logger.error(f"è¿ç§»å¤±è´¥: {migration_file}")
                    return False
            
            # æ›´æ–°åˆ°ç›®æ ‡ç‰ˆæœ¬
            await self.update_schema_version(to_version)
            
            # éªŒè¯å¹¶è¡¥é½å…³é”®æ¨¡æ¿ï¼ˆè¿ç§»æ—¶ç¡®ä¿æ¨¡æ¿å®Œæ•´æ€§ï¼‰
            logger.info("ğŸ“„ éªŒè¯è¿ç§»åæ¨¡æ¿å®Œæ•´æ€§...")
            await self._verify_critical_templates()
            
            # æ‰§è¡ŒSchemaç»“æ„åŒæ­¥æ£€æŸ¥ï¼ˆç¡®ä¿è¿ç§»åæ‰€æœ‰å­—æ®µéƒ½å­˜åœ¨ï¼‰
            logger.info("ğŸ”„ æ‰§è¡Œè¿ç§»åSchemaç»“æ„åŒæ­¥æ£€æŸ¥...")
            schema_sync_success = await schema_sync.synchronize_schema()
            
            if not schema_sync_success:
                logger.warning("SchemaåŒæ­¥å‡ºç°é—®é¢˜ï¼Œä½†ç»§ç»­éªŒè¯è¡¨ç»“æ„")
            
            # éªŒè¯è¿ç§»ç»“æœ
            if await self._verify_tables():
                logger.info(f"âœ… è¿ç§»å®Œæˆ: {to_version}")
                return True
            else:
                logger.error("è¿ç§»åè¡¨éªŒè¯å¤±è´¥")
                return False
                
        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            return False

    def _get_migration_files(self, from_version: str, to_version: str) -> List[str]:
        """
        è·å–éœ€è¦æ‰§è¡Œçš„è¿ç§»æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰ç‰ˆæœ¬æ’åºï¼‰
        """
        if not os.path.exists(self.migrations_dir):
            return []

        pattern = r'migration_(\d{4})_(\d{2})_(\d{2})_(\d+)_.*\.sql'
        files: List[tuple[str, str]] = []  # (version, filename)

        for filename in os.listdir(self.migrations_dir):
            if filename.endswith('.sql') and filename.startswith('migration_'):
                m = re.match(pattern, filename)
                if not m:
                    continue
                year, month, day, num = m.groups()
                file_version = f"{year}.{int(month):02d}.{int(day):02d}.{num}"
                if self._version_compare(file_version, from_version) > 0 and \
                   self._version_compare(file_version, to_version) <= 0:
                    files.append((file_version, filename))

        # æŒ‰ç‰ˆæœ¬ä»å°åˆ°å¤§æ’åºï¼Œç¡®ä¿ 16.15 åœ¨ 16.2 ä¹‹å‰æ‰§è¡Œ
        files.sort(key=lambda x: [int(p) for p in x[0].split('.')])
        return [fn for _, fn in files]

    def _version_compare(self, version1: str, version2: str) -> int:
        """
        æ¯”è¾ƒä¸¤ä¸ªç‰ˆæœ¬å·
        
        Returns:
            1 if version1 > version2
            0 if version1 == version2
            -1 if version1 < version2
        """
        def parse_version(version):
            parts = version.split('.')
            return [int(p) for p in parts]
        
        try:
            v1_parts = parse_version(version1)
            v2_parts = parse_version(version2)
            
            for i in range(max(len(v1_parts), len(v2_parts))):
                v1_part = v1_parts[i] if i < len(v1_parts) else 0
                v2_part = v2_parts[i] if i < len(v2_parts) else 0
                
                if v1_part > v2_part:
                    return 1
                elif v1_part < v2_part:
                    return -1
            
            return 0
        except:
            # å¦‚æœç‰ˆæœ¬æ ¼å¼æœ‰é—®é¢˜ï¼Œé»˜è®¤è®¤ä¸ºç‰ˆæœ¬1æ›´æ–°
            return 1

    async def _auto_generate_migration(self, from_version: str, to_version: str):
        """
        è‡ªåŠ¨ç”Ÿæˆè¿ç§»ï¼ˆå½“æ²¡æœ‰è¿ç§»æ–‡ä»¶æ—¶ï¼‰
        è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿåœ¨å¼€å‘é˜¶æ®µç›´æ¥ä¿®æ”¹schema.sql
        """
        logger.info(f"è‡ªåŠ¨ç”Ÿæˆè¿ç§»: {from_version} -> {to_version}")
        
        # å¼€å‘æ¨¡å¼ï¼šç›´æ¥æ›´æ–°ç‰ˆæœ¬å·ï¼Œç¡®ä¿æœ¬åœ°äº‘ç«¯ä¸€è‡´
        await self.update_schema_version(to_version)
        
        # é‡æ–°æ‰§è¡Œschemaä»¥ç¡®ä¿è¡¨ç»“æ„æœ€æ–°
        schema_path = PathManager.get_database_schema_path()
        if os.path.exists(schema_path):
            with open(schema_path, 'r', encoding='utf-8') as f:
                schema_sql = f.read()
            await self._execute_sql_script(schema_sql)
        
        logger.info("âœ… è‡ªåŠ¨è¿ç§»å®Œæˆï¼ˆç¡®ä¿æœ¬åœ°äº‘ç«¯åŒæ­¥ï¼‰")
    
    async def _initialize_templates(self) -> bool:
        """
        åˆå§‹åŒ–æ¨¡æ¿æ•°æ®
        
        Returns:
            åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–æ¨¡æ¿æ•°æ®...")
            
            # æ£€æŸ¥æ¨¡æ¿è¡¨æ˜¯å¦å­˜åœ¨
            templates_table_check = await db_manager.fetch_one(
                "SELECT name FROM sqlite_master WHERE type='table' AND name='templates'"
            )
            
            if not templates_table_check:
                logger.warning("æ¨¡æ¿è¡¨ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¨¡æ¿åˆå§‹åŒ–")
                return False
            
            # æ‰§è¡Œæ¨¡æ¿æ•°æ®åˆå§‹åŒ–è„šæœ¬
            templates_schema_path = PathManager.get_database_schema_path('schema_templates.sql')
            if os.path.exists(templates_schema_path):
                logger.info("æ‰§è¡Œæ¨¡æ¿æ•°æ®åˆå§‹åŒ–è„šæœ¬...")
                with open(templates_schema_path, 'r', encoding='utf-8') as f:
                    templates_sql = f.read()
                await self._execute_sql_script(templates_sql)
                logger.info("âœ… æ¨¡æ¿æ•°æ®åˆå§‹åŒ–å®Œæˆ")
                
                # éªŒè¯å…³é”®æ¨¡æ¿æ˜¯å¦å­˜åœ¨
                await self._verify_critical_templates()
                return True
            else:
                logger.warning("æ¨¡æ¿åˆå§‹åŒ–è„šæœ¬ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¨¡æ¿åˆå§‹åŒ–")
                return False
                
        except Exception as e:
            logger.error(f"æ¨¡æ¿æ•°æ®åˆå§‹åŒ–å¤±è´¥: {e}")
            return False
    
    async def _verify_critical_templates(self) -> bool:
        """
        éªŒè¯å…³é”®æ¨¡æ¿æ˜¯å¦å­˜åœ¨ï¼Œå¦‚ç¼ºå¤±åˆ™è‡ªåŠ¨è¡¥é½
        
        Returns:
            éªŒè¯æ˜¯å¦æˆåŠŸ
        """
        critical_templates = [
            'binding_code_prompt',
            'error_general', 
            'binding_code_request',
            'invalid_binding_code',
            'channel_post_template',
            'binding_success',
            # ç»‘å®šæµç¨‹æŒ‰é’®ä¸çŠ¶æ€
            'binding_btn_cancel',
            'binding_btn_preview',
            'merchant_registration_pending',
            'binding_callback_failed',
            'system_initializing',
            'quick_bind_success',
            'merchant_already_registered',
            'merchant_account_suspended',
            'merchant_not_registered',
            'error_system',
            # å•†æˆ·é¢æ¿
            'merchant_panel_title',
            'merchant_panel_basic_info',
            'merchant_panel_status_desc',
            'merchant_panel_status_pending_submission',
            'merchant_panel_status_pending_approval',
            'merchant_panel_status_approved',
            'merchant_panel_status_published',
            'merchant_panel_status_expired',
            'merchant_panel_error',
            # å•†æˆ·å¸®åŠ©
            'merchant_help_welcome',
            'merchant_help_register',
            'merchant_help_existing',
            # ç®¡ç†å‘˜
            'admin_unauthorized',
            'admin_help',
            'status_cancelled',
            # ç”¨æˆ·ä¸­å¿ƒä¸æ•°æ®æ ¡éªŒï¼ˆæ ‡å‡† user_* å‰ç¼€ï¼‰
            'user_welcome_message',
            'user_no_profile',
            'data_invalid_format',
            'user_profile_title',
            'user_profile_level',
            'user_profile_xp',
            'user_profile_points',
            'user_profile_orders',
            'user_profile_badges',
            'user_profile_card'
        ]
        
        missing_templates = []
        
        for template_key in critical_templates:
            result = await db_manager.fetch_one(
                "SELECT key FROM templates WHERE key = ?", 
                (template_key,)
            )
            
            if not result:
                missing_templates.append(template_key)
        
        if missing_templates:
            logger.warning(f"æ£€æµ‹åˆ°ç¼ºå¤±çš„å…³é”®æ¨¡æ¿: {missing_templates}")
            
            # è‡ªåŠ¨è¡¥é½ç¼ºå¤±çš„å…³é”®æ¨¡æ¿
            default_templates = {
                'binding_code_prompt': 'ğŸ”‘ è¯·è¾“å…¥æ‚¨çš„ç»‘å®šç ï¼š',
                'error_general': 'âŒ ç³»ç»Ÿæš‚æ—¶æ— æ³•å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·ç¨åé‡è¯•ã€‚',
            'binding_code_request': 'ğŸ”‘ è¦ä¸Šæ¦œï¼Œæ‚¨éœ€è¦ä¸€ä¸ªç»‘å®šç ã€‚è¯·è”ç³»ç®¡ç†å‘˜è·å–æ‚¨çš„ç»‘å®šç ã€‚',
                'invalid_binding_code': 'âŒ ç»‘å®šç æ— æ•ˆæˆ–å·²è¿‡æœŸã€‚è¯·è”ç³»ç®¡ç†å‘˜è·å–æ–°çš„ç»‘å®šç ã€‚',
                'channel_post_template': '{adv_html}\n\nğŸ’ƒğŸ»æ˜µç§°ï¼š{nickname_html}\nğŸŒˆåœ°åŒºï¼š{district_html}\nğŸ«è¯¾è´¹ï¼š{price_p_html}      {price_pp_html}\nğŸ·ï¸æ ‡ç­¾ï¼š{tags_html}\nâœï¸è¯„ä»·ï¼šã€Œ{report_html}ã€\n\nğŸ‰ä¼˜æƒ ï¼š{offer_html}',
                'binding_success': 'ğŸ‰ æ³¨å†ŒæˆåŠŸï¼æ‚¨çš„å•†æˆ·èµ„æ–™å·²æˆåŠŸåˆ›å»ºå¹¶æ¿€æ´»ã€‚',
                # ç»‘å®šæµç¨‹é€šç”¨æŒ‰é’®
                'binding_btn_cancel': 'âŒ å–æ¶ˆæ³¨å†Œ',
                'binding_btn_preview': 'ğŸ“‹ é¢„è§ˆä¿¡æ¯',
                'merchant_registration_pending': 'â³ æ‚¨çš„æ³¨å†Œæ­£åœ¨å¤„ç†ä¸­ï¼Œè¯·ç¨å€™ã€‚',
                'binding_callback_failed': 'å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•',
                'system_initializing': 'ç³»ç»Ÿåˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨å€™â€¦',
                'quick_bind_success': 'ç»‘å®šæˆåŠŸï¼ç³»ç»Ÿå°†å¼•å¯¼ä½ å®Œå–„èµ„æ–™ã€‚',
                'merchant_already_registered': 'æ‚¨å·²æ³¨å†Œï¼Œå½“å‰çŠ¶æ€ï¼š{status_display}',
                'merchant_account_suspended': 'æ‚¨çš„è´¦å·å·²è¢«æš‚åœï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚',
                'merchant_not_registered': 'æ‚¨è¿˜ä¸æ˜¯å•†æˆ·ï¼Œè¯·å…ˆå‘é€â€œä¸Šæ¦œæµç¨‹â€å¹¶å®Œæˆç»‘å®šã€‚',
                'error_system': 'âŒ',
                # å•†æˆ·é¢æ¿
                'merchant_panel_title': 'å•†æˆ·é¢æ¿',
                'merchant_panel_basic_info': 'åŸºæœ¬ä¿¡æ¯',
                'merchant_panel_status_desc': 'çŠ¶æ€è¯´æ˜',
                'merchant_panel_status_pending_submission': 'è¯·åœ¨æœºå™¨äººä¸­ç»§ç»­å®Œå–„ä¿¡æ¯åå†æäº¤å®¡æ ¸ã€‚',
                'merchant_panel_status_pending_approval': 'èµ„æ–™å·²æäº¤ï¼Œç­‰å¾…ç®¡ç†å‘˜å®¡æ ¸ã€‚',
                'merchant_panel_status_approved': 'å·²å®¡æ ¸é€šè¿‡ï¼Œç­‰å¾…å‘å¸ƒã€‚',
                'merchant_panel_status_published': 'å·²å‘å¸ƒï¼Œå½“å‰æ´»è·ƒã€‚',
                'merchant_panel_status_expired': 'å·²è¿‡æœŸæˆ–è¢«æš‚åœã€‚',
                'merchant_panel_error': 'è·å–å•†æˆ·é¢æ¿ä¿¡æ¯å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
                # å•†æˆ·å¸®åŠ©
                'merchant_help_welcome': 'ğŸ‘‹ æ¬¢è¿ä½¿ç”¨å•†æˆ·åŠ©æ‰‹ã€‚',
                'merchant_help_register': 'å‘é€â€œä¸Šæ¦œæµç¨‹â€å¼€å§‹æ³¨å†Œï¼Œæˆ–è¾“å…¥ç»‘å®šç å®Œæˆç»‘å®šã€‚',
                'merchant_help_existing': 'å·²æ³¨å†Œå•†æˆ·è¯·ç‚¹å‡»â€œæˆ‘çš„èµ„æ–™â€æŸ¥çœ‹ä¸ç®¡ç†ã€‚',
                # ç®¡ç†å‘˜
                'admin_unauthorized': 'âŒ ä½ æ²¡æœ‰ç®¡ç†å‘˜æƒé™ã€‚',
                'admin_help': 'ç®¡ç†å‘˜å‘½ä»¤ï¼š/set_button /help ç­‰ã€‚',
                'status_cancelled': 'âŒ æ“ä½œå·²å–æ¶ˆã€‚',
                # ç”¨æˆ·ä¸­å¿ƒä¸æ•°æ®æ ¡éªŒé»˜è®¤æ–‡æ¡ˆ
                'user_welcome_message': 'ğŸ‘‹ æ¬¢è¿ï¼è¿™æ˜¯ä½ çš„ä¸»èœå•ã€‚',
                'user_no_profile': 'â„¹ï¸ æš‚æ— ä¸ªäººèµ„æ–™ï¼Œè¯·å…ˆå®Œå–„ä¿¡æ¯ã€‚',
                'data_invalid_format': 'æ ¼å¼é”™è¯¯',
                'user_profile_title': 'ğŸ“‹ ç”¨æˆ·èµ„æ–™',
                'user_profile_level': 'ç­‰çº§ï¼š{level_name}',
                'user_profile_xp': 'ç»éªŒå€¼ï¼š{xp}',
                'user_profile_points': 'ç§¯åˆ†ï¼š{points}',
                'user_profile_orders': 'å®Œæˆè®¢å•ï¼š{order_count}',
                'user_profile_badges': 'å‹‹ç« ï¼š{badges_text}',
                'user_profile_card': (
                    'ğŸ‘¤ {username}    {level_name}\n'
                    'â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n'
                    '    ğŸ“Š æˆé•¿å€¼\n'
                    '    ğŸ”¥ XP: {xp}    ğŸ’° ç§¯åˆ†: {points}\n\n'
                    '    ğŸ† æˆ˜ç»©: {order_count} èƒœ\n\n'
                    '    ğŸ… å‹‹ç« : {badges_text}\n\n'
                    'â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•'
                )
            }
            
            for template_key in missing_templates:
                if template_key in default_templates:
                    try:
                        await db_manager.execute_query(
                            "INSERT OR IGNORE INTO templates (key, content) VALUES (?, ?)",
                            (
                                template_key,
                                default_templates[template_key]
                            )
                        )
                        logger.info(f"âœ… è‡ªåŠ¨è¡¥é½æ¨¡æ¿: {template_key}")
                    except Exception as e:
                        logger.error(f"è¡¥é½æ¨¡æ¿å¤±è´¥ {template_key}: {e}")
            
            return len(missing_templates) == 0
        else:
            logger.info("âœ… æ‰€æœ‰å…³é”®æ¨¡æ¿éªŒè¯é€šè¿‡")
            # å…¼å®¹æ€§ä¿®æ­£ï¼šå°†å†å²æ¨¡æ¿ä¸­çš„â€œ/panel/å•†æˆ·é¢æ¿â€å¼•å¯¼æ”¹ä¸ºâ€œæˆ‘çš„èµ„æ–™â€æŒ‰é’®
            try:
                row = await db_manager.fetch_one(
                    "SELECT content FROM templates WHERE key = ?",
                    ('merchant_help_existing',)
                )
                if row:
                    content = row['content'] if isinstance(row, dict) else row[0]
                    if isinstance(content, str) and ("/panel" in content or "å•†æˆ·é¢æ¿" in content):
                        new_content = content.replace('/panel', 'ç‚¹å‡»â€œæˆ‘çš„èµ„æ–™â€').replace('å•†æˆ·é¢æ¿', 'â€œæˆ‘çš„èµ„æ–™â€')
                        await db_manager.execute_query(
                            "UPDATE templates SET content = ? WHERE key = ?",
                            (new_content, 'merchant_help_existing')
                        )
                        logger.info("ğŸ”§ å·²æ›´æ–° merchant_help_existing æ¨¡æ¿ä¸ºâ€œæˆ‘çš„èµ„æ–™â€å¼•å¯¼")
            except Exception as e:
                logger.debug(f"æ¨¡æ¿å…¼å®¹ä¿®æ­£è·³è¿‡: {e}")
            return True

    def generate_migration_file(self, description: str) -> str:
        """
        å¼€å‘å·¥å…·ï¼šç”Ÿæˆæ–°çš„è¿ç§»æ–‡ä»¶
        
        Args:
            description: è¿ç§»æè¿°
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„
        """
        # è‡ªåŠ¨ç”Ÿæˆä¸‹ä¸€ä¸ªç‰ˆæœ¬å·
        next_version = self._generate_next_version()
        
        # ç”Ÿæˆæ–‡ä»¶å
        version_parts = next_version.split('.')
        year, month, day, num = version_parts
        
        # æ¸…ç†æè¿°ï¼Œç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å
        safe_desc = re.sub(r'[^\w\u4e00-\u9fff]', '_', description)
        filename = f"migration_{year}_{month}_{day}_{num}_{safe_desc}.sql"
        
        # åˆ›å»ºè¿ç§»ç›®å½•
        PathManager.ensure_directory(self.migrations_dir)
        
        # ç”Ÿæˆè¿ç§»æ–‡ä»¶å†…å®¹
        migration_content = f"""-- {filename}
-- æè¿°: {description}  
-- å‰ç½®ç‰ˆæœ¬: {self.current_schema_version}
-- ç›®æ ‡ç‰ˆæœ¬: {next_version}
-- ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}

-- å‘å‰è¿ç§» (UP)
-- åœ¨è¿™é‡Œæ·»åŠ ä½ çš„æ•°æ®åº“ç»“æ„æ›´æ”¹

-- æ›´æ–°ç‰ˆæœ¬å·
INSERT OR REPLACE INTO system_config (config_key, config_value, description) 
VALUES ('schema_version', '{next_version}', '{description}');

-- å‘åè¿ç§» (DOWN) - å¯é€‰ï¼Œç”¨äºå›æ»š
-- å–æ¶ˆæ³¨é‡Šå¹¶æ·»åŠ å›æ»šé€»è¾‘
-- UPDATE system_config SET config_value = '{self.current_schema_version}' WHERE config_key = 'schema_version';
"""
        
        # å†™å…¥æ–‡ä»¶
        file_path = PathManager.get_database_migration_file_path(filename)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(migration_content)
        
        # æ›´æ–°å½“å‰ä»£ç ä¸­çš„ç‰ˆæœ¬å·
        self.current_schema_version = next_version
        
        logger.info(f"âœ… è¿ç§»æ–‡ä»¶å·²ç”Ÿæˆ: {filename}")
        logger.info(f"ğŸ“ è¯·æ›´æ–°ä»£ç ä¸­çš„ current_schema_version ä¸º: {next_version}")
        return file_path

    def _generate_next_version(self) -> str:
        """è‡ªåŠ¨ç”Ÿæˆä¸‹ä¸€ä¸ªç‰ˆæœ¬å·"""
        today = datetime.now()
        base_version = f"{today.year}.{today.month:02d}.{today.day:02d}"
        
        # æŸ¥æ‰¾ä»Šå¤©å·²æœ‰çš„ç‰ˆæœ¬
        existing_versions = []
        if os.path.exists(self.migrations_dir):
            pattern = r'migration_(\d{4})_(\d{2})_(\d{2})_(\d+)_.*\.sql'
            for filename in os.listdir(self.migrations_dir):
                match = re.match(pattern, filename)
                if match:
                    year, month, day, num = match.groups()
                    if f"{year}.{int(month):02d}.{int(day):02d}" == base_version:
                        existing_versions.append(int(num))
        
        # ç”Ÿæˆä¸‹ä¸€ä¸ªç¼–å·
        next_number = max(existing_versions + [0]) + 1
        return f"{base_version}.{next_number}"
    
    async def get_database_stats(self) -> Dict[str, int]:
        """
        è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            åŒ…å«å„è¡¨è®°å½•æ•°çš„å­—å…¸
        """
        stats = {}
        tables = [
            'merchants', 'orders', 'binding_codes', 'button_configs', 'activity_logs', 'fsm_states',
            'auto_reply_triggers', 'auto_reply_messages', 'auto_reply_daily_stats',
            'cities', 'districts', 'keywords', 'merchant_keywords'
        ]
        
        try:
            for table in tables:
                result = await db_manager.fetch_one(f"SELECT COUNT(*) FROM {table}")
                stats[table] = result[0] if result else 0
            
            logger.debug(f"æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    async def backup_database(self, backup_path: str) -> bool:
        """
        å¤‡ä»½æ•°æ®åº“
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„
            
        Returns:
            å¤‡ä»½æ˜¯å¦æˆåŠŸ
        """
        try:
            import shutil
            
            # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
            PathManager.ensure_parent_directory(backup_path)
            
            # å¤åˆ¶æ•°æ®åº“æ–‡ä»¶
            db_path = db_manager.db_path
            shutil.copy2(db_path, backup_path)
            
            logger.info(f"æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_path}")
            return True
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            return False

    async def _ensure_critical_templates(self):
        """ç¡®ä¿å…³é”®æ¨¡æ¿å­˜åœ¨äºæ•°æ®åº“ä¸­"""
        try:
            from config import MESSAGE_TEMPLATES
            
            # éœ€è¦åŒæ­¥åˆ°æ•°æ®åº“çš„å…³é”®æ¨¡æ¿
            critical_templates = [
                "channel_info_display",
                "channel_click_notification", 
                "order_notification_merchant"
            ]
            
            for template_key in critical_templates:
                # æ£€æŸ¥æ¨¡æ¿æ˜¯å¦å·²å­˜åœ¨äºæ•°æ®åº“
                result = await db_manager.fetch_one(
                    "SELECT key FROM templates WHERE key = ?",
                    (template_key,)
                )
                
                if not result:
                    # ä»config.pyè·å–æ¨¡æ¿å†…å®¹
                    template_content = MESSAGE_TEMPLATES.get(template_key)
                    if template_content:
                        logger.info(f"æ·»åŠ ç¼ºå¤±çš„{template_key}æ¨¡æ¿")
                        await db_manager.execute_query(
                            "INSERT OR IGNORE INTO templates (key, content) VALUES (?, ?)",
                            (template_key, template_content.strip())
                        )
                        logger.info(f"âœ… {template_key}æ¨¡æ¿æ·»åŠ æˆåŠŸ")
                    else:
                        logger.warning(f"config.pyä¸­æœªæ‰¾åˆ°{template_key}æ¨¡æ¿å®šä¹‰")
                else:
                    logger.debug(f"{template_key}æ¨¡æ¿å·²å­˜åœ¨")
                
        except Exception as e:
            logger.error(f"ç¡®ä¿å…³é”®æ¨¡æ¿å­˜åœ¨å¤±è´¥: {e}")
            # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“ç³»ç»Ÿå¯åŠ¨

# åˆ›å»ºå…¨å±€æ•°æ®åº“åˆå§‹åŒ–å™¨å®ä¾‹
db_initializer = DatabaseInitializer()

async def init_database() -> bool:
    """
    åˆå§‹åŒ–æ•°æ®åº“çš„ä¾¿æ·å‡½æ•°
    
    Returns:
        åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
    """
    return await db_initializer.initialize_database()

async def cleanup_database():
    """æ¸…ç†æ•°æ®åº“çš„ä¾¿æ·å‡½æ•°"""
    await db_initializer.cleanup_expired_data()

async def get_db_stats() -> Dict[str, int]:
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯çš„ä¾¿æ·å‡½æ•°"""
    return await db_initializer.get_database_stats()
