"""
ç»Ÿè®¡å’ŒæŠ¥å‘Šç³»ç»Ÿæ¨¡å—
æä¾›å…¨é¢çš„ç»Ÿè®¡æ•°æ®ç”Ÿæˆã€æ—¶é—´å’ŒæŒ‰é’®è¿‡æ»¤ã€æ•°æ®èšåˆå’Œè¶‹åŠ¿åˆ†æåŠŸèƒ½
æ”¯æŒå¤šç§ç»Ÿè®¡ç±»å‹å’Œæ ¼å¼åŒ–è¾“å‡º
"""

import logging
from typing import Dict, List, Optional, Any, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass
from enum import Enum

from utils.enums import MERCHANT_STATUS

# æ•°æ®åº“ç®¡ç†å™¨å¯¼å…¥
from database.db_logs import ActivityLogsDatabase, activity_logs_db
from database.db_binding_codes import BindingCodesDatabase, binding_codes_db
from database.db_merchants import MerchantManager, merchant_manager
from database.db_orders import OrderManager, order_manager
from database.db_templates import template_manager

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class StatsPeriod(Enum):
    """ç»Ÿè®¡æ—¶é—´å‘¨æœŸæšä¸¾"""

    TODAY = "today"
    YESTERDAY = "yesterday"
    WEEK = "week"
    MONTH = "month"
    QUARTER = "quarter"
    YEAR = "year"
    ALL_TIME = "all_time"
    CUSTOM = "custom"


class StatsType(Enum):
    """ç»Ÿè®¡ç±»å‹æšä¸¾"""

    BUTTON_CLICKS = "button_clicks"
    USER_ACTIVITY = "user_activity"
    MERCHANT_PERFORMANCE = "merchant_performance"
    ORDER_ANALYTICS = "order_analytics"
    BINDING_CODES = "binding_codes"
    SYSTEM_HEALTH = "system_health"
    COMPREHENSIVE = "comprehensive"


@dataclass
class TimeRange:
    """æ—¶é—´èŒƒå›´æ•°æ®ç±»"""

    start_date: datetime
    end_date: datetime
    period_name: str

    def to_dict(self) -> Dict[str, Any]:
        return {
            "start_date": self.start_date.isoformat(),
            "end_date": self.end_date.isoformat(),
            "period_name": self.period_name,
        }


@dataclass
class StatsResult:
    """ç»Ÿè®¡ç»“æœæ•°æ®ç±»"""

    stats_type: str
    time_range: TimeRange
    data: Dict[str, Any]
    generated_at: datetime

    def to_dict(self) -> Dict[str, Any]:
        return {
            "stats_type": self.stats_type,
            "time_range": self.time_range.to_dict(),
            "data": self.data,
            "generated_at": self.generated_at.isoformat(),
        }


class StatisticsEngine:
    """
    ç»Ÿè®¡å¼•æ“ç±»
    æä¾›å…¨é¢çš„ç»Ÿè®¡æ•°æ®ç”Ÿæˆå’Œåˆ†æåŠŸèƒ½
    """

    @staticmethod
    def get_time_range(
        period: StatsPeriod,
        custom_start: Optional[datetime] = None,
        custom_end: Optional[datetime] = None,
    ) -> TimeRange:
        """
        æ ¹æ®å‘¨æœŸè·å–æ—¶é—´èŒƒå›´

        Args:
            period: ç»Ÿè®¡å‘¨æœŸ
            custom_start: è‡ªå®šä¹‰å¼€å§‹æ—¶é—´
            custom_end: è‡ªå®šä¹‰ç»“æŸæ—¶é—´

        Returns:
            æ—¶é—´èŒƒå›´å¯¹è±¡
        """
        now = datetime.now()

        if period == StatsPeriod.TODAY:
            start_date = now.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = now
            period_name = "ä»Šæ—¥"

        elif period == StatsPeriod.YESTERDAY:
            yesterday = now - timedelta(days=1)
            start_date = yesterday.replace(hour=0, minute=0, second=0, microsecond=0)
            end_date = yesterday.replace(
                hour=23, minute=59, second=59, microsecond=999999
            )
            period_name = "æ˜¨æ—¥"

        elif period == StatsPeriod.WEEK:
            # æœ¬å‘¨ï¼ˆå‘¨ä¸€åˆ°ç°åœ¨ï¼‰
            days_since_monday = now.weekday()
            start_date = (now - timedelta(days=days_since_monday)).replace(
                hour=0, minute=0, second=0, microsecond=0
            )
            end_date = now
            period_name = "æœ¬å‘¨"

        elif period == StatsPeriod.MONTH:
            # æœ¬æœˆ
            start_date = now.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
            end_date = now
            period_name = "æœ¬æœˆ"

        elif period == StatsPeriod.QUARTER:
            # æœ¬å­£åº¦
            quarter_start_month = ((now.month - 1) // 3) * 3 + 1
            start_date = now.replace(
                month=quarter_start_month,
                day=1,
                hour=0,
                minute=0,
                second=0,
                microsecond=0,
            )
            end_date = now
            period_name = "æœ¬å­£åº¦"

        elif period == StatsPeriod.YEAR:
            # æœ¬å¹´
            start_date = now.replace(
                month=1, day=1, hour=0, minute=0, second=0, microsecond=0
            )
            end_date = now
            period_name = "æœ¬å¹´"

        elif period == StatsPeriod.CUSTOM:
            # è‡ªå®šä¹‰æ—¶é—´èŒƒå›´
            if not custom_start or not custom_end:
                raise ValueError("è‡ªå®šä¹‰æ—¶é—´èŒƒå›´éœ€è¦æä¾›å¼€å§‹å’Œç»“æŸæ—¶é—´")
            start_date = custom_start
            end_date = custom_end
            period_name = (
                f"{start_date.strftime('%Y-%m-%d')} è‡³ {end_date.strftime('%Y-%m-%d')}"
            )

        else:  # ALL_TIME
            start_date = datetime(2020, 1, 1)  # å‡è®¾ç³»ç»Ÿä»2020å¹´å¼€å§‹
            end_date = now
            period_name = "å…¨éƒ¨æ—¶é—´"

        return TimeRange(start_date, end_date, period_name)

    @staticmethod
    async def generate_button_click_analytics(
        time_range: TimeRange,
        button_filter: Optional[str] = None,
        merchant_filter: Optional[int] = None,
    ) -> Dict[str, Any]:
        """
        ç”ŸæˆæŒ‰é’®ç‚¹å‡»åˆ†ææ•°æ®ï¼ˆçº¯è°ƒç”¨å±‚ï¼‰

        Args:
            time_range: æ—¶é—´èŒƒå›´
            button_filter: æŒ‰é’®è¿‡æ»¤å™¨
            merchant_filter: å•†æˆ·è¿‡æ»¤å™¨

        Returns:
            æŒ‰é’®ç‚¹å‡»åˆ†ææ•°æ®
        """
        try:
            # ç›´æ¥è°ƒç”¨æ´»åŠ¨æ—¥å¿—ç®¡ç†å™¨çš„é«˜æ•ˆèšåˆæŸ¥è¯¢æ–¹æ³•
            analytics_data = (
                await ActivityLogsDatabase.get_comprehensive_button_analytics(
                    start_date=time_range.start_date,
                    end_date=time_range.end_date,
                    button_filter=button_filter,
                    merchant_filter=merchant_filter,
                )
            )

            # æ·»åŠ æ—¶é—´èŒƒå›´ä¿¡æ¯
            analytics_data["time_range"] = time_range.to_dict()

            logger.info(f"æŒ‰é’®ç‚¹å‡»åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”ŸæˆæŒ‰é’®ç‚¹å‡»åˆ†æå¤±è´¥: {e}")
            raise

    @staticmethod
    async def generate_user_activity_analytics(
        time_range: TimeRange, user_filter: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆç”¨æˆ·æ´»åŠ¨åˆ†ææ•°æ®

        Args:
            time_range: æ—¶é—´èŒƒå›´
            user_filter: ç”¨æˆ·è¿‡æ»¤å™¨

        Returns:
            ç”¨æˆ·æ´»åŠ¨åˆ†ææ•°æ®
        """
        try:
            # è·å–æ´»åŠ¨ç»Ÿè®¡
            activity_stats = await ActivityLogsDatabase.get_activity_statistics(
                start_date=time_range.start_date, end_date=time_range.end_date
            )

            # ç”¨æˆ·åˆ†å±‚åˆ†æ
            user_segments = await StatisticsEngine._analyze_user_segments(time_range)

            # ç”¨æˆ·ç•™å­˜åˆ†æ
            retention_analysis = await StatisticsEngine._calculate_user_retention(
                time_range
            )

            # æ´»åŠ¨ç±»å‹åˆ†å¸ƒ
            activity_distribution = activity_stats["action_type_stats"]

            # ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸåˆ†æ
            lifecycle_analysis = await StatisticsEngine._analyze_user_lifecycle(
                time_range
            )

            analytics_data = {
                "basic_metrics": {
                    "total_activities": activity_stats["total_activities"],
                    "active_users": activity_stats["active_users"],
                    "average_activities_per_user": activity_stats["total_activities"]
                    / max(activity_stats["active_users"], 1),
                },
                "top_users": activity_stats["top_users"],
                "activity_distribution": activity_distribution,
                "daily_activity": activity_stats["daily_activity"],
                "user_segments": user_segments,
                "retention_analysis": retention_analysis,
                "lifecycle_analysis": lifecycle_analysis,
                "time_range": time_range.to_dict(),
            }

            logger.info(f"ç”¨æˆ·æ´»åŠ¨åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆç”¨æˆ·æ´»åŠ¨åˆ†æå¤±è´¥: {e}")
            raise

    @staticmethod
    async def generate_merchant_performance_analytics(
        time_range: TimeRange, merchant_filter: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆå•†æˆ·è¡¨ç°åˆ†ææ•°æ®ï¼ˆçº¯è°ƒç”¨å±‚ï¼‰

        Args:
            time_range: æ—¶é—´èŒƒå›´
            merchant_filter: å•†æˆ·è¿‡æ»¤å™¨

        Returns:
            å•†æˆ·è¡¨ç°åˆ†ææ•°æ®
        """
        try:
            # ç›´æ¥è°ƒç”¨ç®¡ç†å™¨çš„é«˜æ•ˆèšåˆæŸ¥è¯¢æ–¹æ³•
            analytics_data = await MerchantManager.get_merchant_performance_analytics(
                start_date=time_range.start_date,
                end_date=time_range.end_date,
                merchant_filter=merchant_filter,
            )

            # æ·»åŠ æ—¶é—´èŒƒå›´ä¿¡æ¯
            analytics_data["time_range"] = time_range.to_dict()

            logger.info(f"å•†æˆ·è¡¨ç°åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆå•†æˆ·è¡¨ç°åˆ†æå¤±è´¥: {e}")
            raise

    @staticmethod
    async def generate_order_analytics(
        time_range: TimeRange, merchant_filter: Optional[int] = None
    ) -> Dict[str, Any]:
        """
        ç”Ÿæˆè®¢å•åˆ†ææ•°æ®

        Args:
            time_range: æ—¶é—´èŒƒå›´
            merchant_filter: å•†æˆ·è¿‡æ»¤å™¨

        Returns:
            è®¢å•åˆ†ææ•°æ®
        """
        try:
            # è·å–è®¢å•æ•°æ®
            if merchant_filter:
                orders = await OrderManager.get_orders_by_merchant(merchant_filter)
            else:
                orders = await OrderManager.get_orders_by_timeframe(
                    time_range.start_date, time_range.end_date
                )

            # åŸºç¡€æŒ‡æ ‡
            total_orders = len(orders)
            completed_orders = len([o for o in orders if o["status"] == "completed"])
            pending_orders = len([o for o in orders if o["status"] == "pending"])

            # è®¢å•ç±»å‹åˆ†æ
            order_type_stats = {}
            for order in orders:
                order_type = order.get("order_type", "æœªçŸ¥")
                order_type_stats[order_type] = order_type_stats.get(order_type, 0) + 1

            # æ—¶é—´åˆ†å¸ƒåˆ†æ
            daily_orders = {}
            hourly_orders = {}

            for order in orders:
                order_date = datetime.fromisoformat(order["created_at"])
                date_key = order_date.strftime("%Y-%m-%d")
                hour_key = order_date.strftime("%H:00")

                daily_orders[date_key] = daily_orders.get(date_key, 0) + 1
                hourly_orders[hour_key] = hourly_orders.get(hour_key, 0) + 1

            # å•†æˆ·è®¢å•åˆ†å¸ƒ
            merchant_order_stats = {}
            for order in orders:
                merchant_id = order["merchant_id"]
                merchant_order_stats[merchant_id] = (
                    merchant_order_stats.get(merchant_id, 0) + 1
                )

            # ä»·æ ¼åˆ†æï¼ˆå¦‚æœæœ‰ä»·æ ¼æ•°æ®ï¼‰
            price_analysis = await StatisticsEngine._analyze_order_prices(orders)

            # å®Œæˆç‡åˆ†æ
            completion_rate = (completed_orders / max(total_orders, 1)) * 100

            analytics_data = {
                "basic_metrics": {
                    "total_orders": total_orders,
                    "completed_orders": completed_orders,
                    "pending_orders": pending_orders,
                    "completion_rate": completion_rate,
                },
                "order_type_distribution": order_type_stats,
                "daily_distribution": daily_orders,
                "hourly_distribution": hourly_orders,
                "merchant_distribution": merchant_order_stats,
                "price_analysis": price_analysis,
                "time_range": time_range.to_dict(),
            }

            logger.info(f"è®¢å•åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆè®¢å•åˆ†æå¤±è´¥: {e}")
            raise

    @staticmethod
    async def generate_binding_code_analytics(time_range: TimeRange) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»‘å®šç åˆ†ææ•°æ®

        Args:
            time_range: æ—¶é—´èŒƒå›´

        Returns:
            ç»‘å®šç åˆ†ææ•°æ®
        """
        try:
            # è·å–ç»‘å®šç ç»Ÿè®¡
            binding_stats = await BindingCodesDatabase.get_binding_code_statistics()

            # è·å–æ‰€æœ‰ç»‘å®šç 
            all_codes = await BindingCodesDatabase.get_all_binding_codes(
                include_used=True, include_expired=True
            )

            # æ—¶é—´èŒƒå›´å†…çš„ç»‘å®šç 
            period_codes = [
                code
                for code in all_codes
                if time_range.start_date
                <= datetime.fromisoformat(code["created_at"])
                <= time_range.end_date
            ]

            # ä½¿ç”¨æƒ…å†µåˆ†æ
            period_used = len([c for c in period_codes if c["is_used"]])
            period_expired = len(
                [
                    c
                    for c in period_codes
                    if c["expires_at"]
                    and datetime.fromisoformat(c["expires_at"]) < datetime.now()
                    and not c["is_used"]
                ]
            )

            # ä½¿ç”¨æ—¶é—´åˆ†æ
            usage_time_analysis = await StatisticsEngine._analyze_code_usage_time(
                period_codes
            )

            # æ¯æ—¥ç”Ÿæˆå’Œä½¿ç”¨è¶‹åŠ¿
            daily_generation = {}
            daily_usage = {}

            for code in period_codes:
                gen_date = datetime.fromisoformat(code["created_at"]).strftime(
                    "%Y-%m-%d"
                )
                daily_generation[gen_date] = daily_generation.get(gen_date, 0) + 1

                if code["is_used"] and code.get("used_at"):
                    use_date = datetime.fromisoformat(code["used_at"]).strftime(
                        "%Y-%m-%d"
                    )
                    daily_usage[use_date] = daily_usage.get(use_date, 0) + 1

            analytics_data = {
                "basic_metrics": {
                    "total_generated": len(period_codes),
                    "total_used": period_used,
                    "total_expired": period_expired,
                    "usage_rate": (period_used / max(len(period_codes), 1)) * 100,
                    "expiry_rate": (period_expired / max(len(period_codes), 1)) * 100,
                },
                "overall_stats": binding_stats,
                "daily_generation": daily_generation,
                "daily_usage": daily_usage,
                "usage_time_analysis": usage_time_analysis,
                "time_range": time_range.to_dict(),
            }

            logger.info(f"ç»‘å®šç åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆç»‘å®šç åˆ†æå¤±è´¥: {e}")
            raise

    @staticmethod
    async def generate_system_health_analytics(time_range: TimeRange) -> Dict[str, Any]:
        """
        ç”Ÿæˆç³»ç»Ÿå¥åº·åº¦åˆ†ææ•°æ®

        Args:
            time_range: æ—¶é—´èŒƒå›´

        Returns:
            ç³»ç»Ÿå¥åº·åº¦åˆ†ææ•°æ®
        """
        try:
            # è·å–å„ç±»ç»Ÿè®¡æ•°æ®
            button_stats = await ActivityLogsDatabase.get_button_click_statistics(
                start_date=time_range.start_date, end_date=time_range.end_date
            )

            activity_stats = await ActivityLogsDatabase.get_activity_statistics(
                start_date=time_range.start_date, end_date=time_range.end_date
            )

            merchants = await MerchantManager.get_all_merchants()
            orders = await OrderManager.get_orders_by_timeframe(
                time_range.start_date, time_range.end_date
            )

            binding_stats = await BindingCodesDatabase.get_binding_code_statistics()

            # è®¡ç®—å¥åº·åº¦æŒ‡æ ‡
            active_merchants = len([m for m in merchants if m["status"] == "active"])
            merchant_activation_rate = (active_merchants / max(len(merchants), 1)) * 100

            user_engagement_rate = (
                activity_stats["active_users"] / max(button_stats["unique_users"], 1)
            ) * 100

            order_conversion_rate = (
                len(orders) / max(button_stats["total_clicks"], 1)
            ) * 100

            binding_code_efficiency = binding_stats["usage_rate"]

            # ç³»ç»Ÿæ´»è·ƒåº¦
            system_activity_score = min(
                100,
                (
                    merchant_activation_rate * 0.3
                    + user_engagement_rate * 0.3
                    + order_conversion_rate * 0.2
                    + binding_code_efficiency * 0.2
                ),
            )

            # é”™è¯¯ç‡åˆ†æ
            error_logs = await ActivityLogsDatabase.get_recent_activities(
                limit=1000, action_type="error_event"
            )

            period_errors = [
                log
                for log in error_logs
                if time_range.start_date
                <= datetime.fromisoformat(log["timestamp"])
                <= time_range.end_date
            ]

            error_rate = (
                len(period_errors) / max(activity_stats["total_activities"], 1)
            ) * 100

            # æ€§èƒ½æŒ‡æ ‡
            performance_metrics = {
                "average_response_time": 0,  # éœ€è¦å®é™…æµ‹é‡
                "uptime_percentage": 99.9,  # éœ€è¦å®é™…ç›‘æ§
                "concurrent_users": button_stats["unique_users"],
            }

            analytics_data = {
                "health_score": {
                    "overall_score": system_activity_score,
                    "merchant_activation_rate": merchant_activation_rate,
                    "user_engagement_rate": user_engagement_rate,
                    "order_conversion_rate": order_conversion_rate,
                    "binding_code_efficiency": binding_code_efficiency,
                },
                "system_metrics": {
                    "total_merchants": len(merchants),
                    "active_merchants": active_merchants,
                    "total_users": button_stats["unique_users"],
                    "active_users": activity_stats["active_users"],
                    "total_orders": len(orders),
                    "error_rate": error_rate,
                },
                "performance_metrics": performance_metrics,
                "error_analysis": {
                    "total_errors": len(period_errors),
                    "error_rate": error_rate,
                    "error_types": {},  # å¯ä»¥è¿›ä¸€æ­¥åˆ†æé”™è¯¯ç±»å‹
                },
                "time_range": time_range.to_dict(),
            }

            logger.info(f"ç³»ç»Ÿå¥åº·åº¦åˆ†æç”Ÿæˆå®Œæˆï¼Œæ—¶é—´èŒƒå›´: {time_range.period_name}")
            return analytics_data

        except Exception as e:
            logger.error(f"ç”Ÿæˆç³»ç»Ÿå¥åº·åº¦åˆ†æå¤±è´¥: {e}")
            raise

    # è¾…åŠ©åˆ†ææ–¹æ³•
    @staticmethod
    async def _calculate_engagement_metrics(
        time_range: TimeRange, button_stats: Dict[str, Any]
    ) -> Dict[str, Any]:
        """è®¡ç®—ç”¨æˆ·å‚ä¸åº¦æŒ‡æ ‡"""
        try:
            total_clicks = button_stats["total_clicks"]
            unique_users = button_stats["unique_users"]

            # å‚ä¸åº¦æŒ‡æ ‡
            engagement_metrics = {
                "click_frequency": total_clicks / max(unique_users, 1),
                "user_retention_rate": 0,  # éœ€è¦æ›´å¤æ‚çš„è®¡ç®—
                "session_duration": 0,  # éœ€è¦ä¼šè¯è·Ÿè¸ª
                "bounce_rate": 0,  # éœ€è¦å®šä¹‰è·³å‡ºæ ‡å‡†
            }

            return engagement_metrics

        except Exception as e:
            logger.error(f"è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _calculate_trend_analysis(
        time_range: TimeRange, daily_stats: Dict[str, int]
    ) -> Dict[str, Any]:
        """è®¡ç®—è¶‹åŠ¿åˆ†æ"""
        try:
            if not daily_stats or len(daily_stats) < 2:
                return {"trend": "insufficient_data", "growth_rate": 0}

            # æŒ‰æ—¥æœŸæ’åº
            sorted_dates = sorted(daily_stats.keys())
            values = [daily_stats[date] for date in sorted_dates]

            # è®¡ç®—å¢é•¿ç‡
            if len(values) >= 2:
                recent_avg = sum(values[-3:]) / min(3, len(values))
                earlier_avg = sum(values[:3]) / min(3, len(values))

                if earlier_avg > 0:
                    growth_rate = ((recent_avg - earlier_avg) / earlier_avg) * 100
                else:
                    growth_rate = 0

                # åˆ¤æ–­è¶‹åŠ¿
                if growth_rate > 10:
                    trend = "increasing"
                elif growth_rate < -10:
                    trend = "decreasing"
                else:
                    trend = "stable"
            else:
                growth_rate = 0
                trend = "stable"

            return {
                "trend": trend,
                "growth_rate": growth_rate,
                "data_points": len(values),
            }

        except Exception as e:
            logger.error(f"è®¡ç®—è¶‹åŠ¿åˆ†æå¤±è´¥: {e}")
            return {"trend": "error", "growth_rate": 0}

    @staticmethod
    async def _analyze_peak_hours(
        time_range: TimeRange, hourly_stats: Dict[str, int]
    ) -> Dict[str, Any]:
        """åˆ†æé«˜å³°æ—¶æ®µ"""
        try:
            if not hourly_stats:
                return {"peak_hour": None, "peak_clicks": 0, "quiet_hour": None}

            # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½æ´»è·ƒæ—¶æ®µ
            sorted_hours = sorted(
                hourly_stats.items(), key=lambda x: x[1], reverse=True
            )

            peak_analysis = {
                "peak_hour": sorted_hours[0][0] if sorted_hours else None,
                "peak_clicks": sorted_hours[0][1] if sorted_hours else 0,
                "quiet_hour": sorted_hours[-1][0] if sorted_hours else None,
                "quiet_clicks": sorted_hours[-1][1] if sorted_hours else 0,
                "hourly_distribution": hourly_stats,
            }

            return peak_analysis

        except Exception as e:
            logger.error(f"åˆ†æé«˜å³°æ—¶æ®µå¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_user_segments(time_range: TimeRange) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·åˆ†å±‚"""
        try:
            # è·å–ç”¨æˆ·æ´»åŠ¨æ•°æ®
            recent_activities = await ActivityLogsDatabase.get_recent_activities(
                limit=10000
            )

            # æŒ‰ç”¨æˆ·åˆ†ç»„ç»Ÿè®¡
            user_activity_count = {}
            for activity in recent_activities:
                if activity["user_id"]:
                    user_id = activity["user_id"]
                    user_activity_count[user_id] = (
                        user_activity_count.get(user_id, 0) + 1
                    )

            # ç”¨æˆ·åˆ†å±‚
            high_activity_users = len(
                [u for u in user_activity_count.values() if u >= 10]
            )
            medium_activity_users = len(
                [u for u in user_activity_count.values() if 3 <= u < 10]
            )
            low_activity_users = len([u for u in user_activity_count.values() if u < 3])

            segments = {
                "high_activity": high_activity_users,
                "medium_activity": medium_activity_users,
                "low_activity": low_activity_users,
                "total_users": len(user_activity_count),
            }

            return segments

        except Exception as e:
            logger.error(f"åˆ†æç”¨æˆ·åˆ†å±‚å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _calculate_user_retention(time_range: TimeRange) -> Dict[str, Any]:
        """è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡"""
        try:
            # ç®€åŒ–çš„ç•™å­˜ç‡è®¡ç®—
            # å®é™…å®ç°éœ€è¦æ›´å¤æ‚çš„ç”¨æˆ·è¡Œä¸ºè·Ÿè¸ª
            retention_analysis = {
                "day_1_retention": 0,
                "day_7_retention": 0,
                "day_30_retention": 0,
                "note": "éœ€è¦æ›´é•¿æ—¶é—´çš„æ•°æ®ç§¯ç´¯æ¥è®¡ç®—å‡†ç¡®çš„ç•™å­˜ç‡",
            }

            return retention_analysis

        except Exception as e:
            logger.error(f"è®¡ç®—ç”¨æˆ·ç•™å­˜ç‡å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_user_lifecycle(time_range: TimeRange) -> Dict[str, Any]:
        """åˆ†æç”¨æˆ·ç”Ÿå‘½å‘¨æœŸ"""
        try:
            # ç”¨æˆ·ç”Ÿå‘½å‘¨æœŸåˆ†æ
            lifecycle_analysis = {
                "new_users": 0,
                "active_users": 0,
                "returning_users": 0,
                "churned_users": 0,
                "note": "éœ€è¦ç”¨æˆ·é¦–æ¬¡è®¿é—®æ—¶é—´æ•°æ®æ¥è¿›è¡Œå‡†ç¡®åˆ†æ",
            }

            return lifecycle_analysis

        except Exception as e:
            logger.error(f"åˆ†æç”¨æˆ·ç”Ÿå‘½å‘¨æœŸå¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_merchant_by_region(
        merchant_metrics: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æŒ‰åœ°åŒºåˆ†æå•†æˆ·"""
        try:
            region_stats = {}
            for merchant in merchant_metrics:
                # ä½¿ç”¨ç»“æ„åŒ–åœ°åŒºåç§°
                region = merchant.get("region_display") or "æœªè®¾ç½®"
                if region not in region_stats:
                    region_stats[region] = {
                        "merchant_count": 0,
                        "total_interactions": 0,
                        "total_orders": 0,
                    }

                region_stats[region]["merchant_count"] += 1
                region_stats[region]["total_interactions"] += merchant[
                    "total_interactions"
                ]
                region_stats[region]["total_orders"] += merchant["total_orders"]

            # è®¡ç®—å¹³å‡å€¼
            for region, stats in region_stats.items():
                stats["avg_interactions"] = (
                    stats["total_interactions"] / stats["merchant_count"]
                )
                stats["avg_orders"] = stats["total_orders"] / stats["merchant_count"]

            return region_stats

        except Exception as e:
            logger.error(f"æŒ‰åœ°åŒºåˆ†æå•†æˆ·å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_merchant_by_category(
        merchant_metrics: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """æŒ‰ç±»åˆ«åˆ†æå•†æˆ·"""
        try:
            category_stats = {}
            for merchant in merchant_metrics:
                # ä½¿ç”¨ç»“æ„åŒ–ç±»å‹ merchant_type ä»£æ›¿æ—§ category
                category = merchant.get("merchant_type") or "unknown"
                if category not in category_stats:
                    category_stats[category] = {
                        "merchant_count": 0,
                        "total_interactions": 0,
                        "total_orders": 0,
                    }

                category_stats[category]["merchant_count"] += 1
                category_stats[category]["total_interactions"] += merchant[
                    "total_interactions"
                ]
                category_stats[category]["total_orders"] += merchant["total_orders"]

            # è®¡ç®—å¹³å‡å€¼
            for category, stats in category_stats.items():
                stats["avg_interactions"] = (
                    stats["total_interactions"] / stats["merchant_count"]
                )
                stats["avg_orders"] = stats["total_orders"] / stats["merchant_count"]

            return category_stats

        except Exception as e:
            logger.error(f"æŒ‰ç±»åˆ«åˆ†æå•†æˆ·å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _categorize_merchant_performance(
        merchant_metrics: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å•†æˆ·è¡¨ç°åˆ†å±‚"""
        try:
            if not merchant_metrics:
                return {}

            # æŒ‰äº¤äº’æ•°æ’åº
            sorted_merchants = sorted(
                merchant_metrics, key=lambda x: x["total_interactions"], reverse=True
            )
            total_merchants = len(sorted_merchants)

            # åˆ†å±‚æ ‡å‡†ï¼ˆåŸºäºäº¤äº’æ•°ï¼‰
            high_performers = []
            medium_performers = []
            low_performers = []

            for merchant in sorted_merchants:
                interactions = merchant["total_interactions"]
                if interactions >= 50:  # é«˜è¡¨ç°å•†æˆ·
                    high_performers.append(merchant)
                elif interactions >= 10:  # ä¸­ç­‰è¡¨ç°å•†æˆ·
                    medium_performers.append(merchant)
                else:  # ä½è¡¨ç°å•†æˆ·
                    low_performers.append(merchant)

            performance_tiers = {
                "high_performers": {
                    "count": len(high_performers),
                    "percentage": (len(high_performers) / total_merchants) * 100
                    if total_merchants > 0
                    else 0,
                    "avg_interactions": sum(
                        m["total_interactions"] for m in high_performers
                    )
                    / len(high_performers)
                    if high_performers
                    else 0,
                    "avg_orders": sum(m["total_orders"] for m in high_performers)
                    / len(high_performers)
                    if high_performers
                    else 0,
                },
                "medium_performers": {
                    "count": len(medium_performers),
                    "percentage": (len(medium_performers) / total_merchants) * 100
                    if total_merchants > 0
                    else 0,
                    "avg_interactions": sum(
                        m["total_interactions"] for m in medium_performers
                    )
                    / len(medium_performers)
                    if medium_performers
                    else 0,
                    "avg_orders": sum(m["total_orders"] for m in medium_performers)
                    / len(medium_performers)
                    if medium_performers
                    else 0,
                },
                "low_performers": {
                    "count": len(low_performers),
                    "percentage": (len(low_performers) / total_merchants) * 100
                    if total_merchants > 0
                    else 0,
                    "avg_interactions": sum(
                        m["total_interactions"] for m in low_performers
                    )
                    / len(low_performers)
                    if low_performers
                    else 0,
                    "avg_orders": sum(m["total_orders"] for m in low_performers)
                    / len(low_performers)
                    if low_performers
                    else 0,
                },
            }

            return performance_tiers

        except Exception as e:
            logger.error(f"å•†æˆ·è¡¨ç°åˆ†å±‚å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_order_prices(orders: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æè®¢å•ä»·æ ¼"""
        try:
            orders_with_price = [
                order
                for order in orders
                if order.get("price") and float(order["price"]) > 0
            ]

            if not orders_with_price:
                return {
                    "total_orders_with_price": 0,
                    "average_price": 0,
                    "total_revenue": 0,
                    "min_price": 0,
                    "max_price": 0,
                }

            prices = [float(order["price"]) for order in orders_with_price]

            price_analysis = {
                "total_orders_with_price": len(orders_with_price),
                "average_price": sum(prices) / len(prices),
                "total_revenue": sum(prices),
                "min_price": min(prices),
                "max_price": max(prices),
                "price_ranges": {
                    "under_100": len([p for p in prices if p < 100]),
                    "100_to_500": len([p for p in prices if 100 <= p < 500]),
                    "500_to_1000": len([p for p in prices if 500 <= p < 1000]),
                    "over_1000": len([p for p in prices if p >= 1000]),
                },
            }

            return price_analysis

        except Exception as e:
            logger.error(f"åˆ†æè®¢å•ä»·æ ¼å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_code_usage_time(codes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç»‘å®šç ä½¿ç”¨æ—¶é—´"""
        try:
            used_codes = [
                code for code in codes if code["is_used"] and code.get("used_at")
            ]

            if not used_codes:
                return {
                    "average_usage_time": 0,
                    "quick_usage_count": 0,
                    "delayed_usage_count": 0,
                    "usage_time_distribution": {},
                }

            usage_times = []
            quick_usage_count = 0
            delayed_usage_count = 0

            for code in used_codes:
                created_at = datetime.fromisoformat(code["created_at"])
                used_at = datetime.fromisoformat(code["used_at"])
                usage_time_hours = (used_at - created_at).total_seconds() / 3600

                usage_times.append(usage_time_hours)

                if usage_time_hours <= 1:  # 1å°æ—¶å†…ä½¿ç”¨
                    quick_usage_count += 1
                elif usage_time_hours >= 24:  # 24å°æ—¶åä½¿ç”¨
                    delayed_usage_count += 1

            # ä½¿ç”¨æ—¶é—´åˆ†å¸ƒ
            usage_time_distribution = {
                "within_1_hour": len([t for t in usage_times if t <= 1]),
                "1_to_6_hours": len([t for t in usage_times if 1 < t <= 6]),
                "6_to_24_hours": len([t for t in usage_times if 6 < t <= 24]),
                "1_to_7_days": len([t for t in usage_times if 24 < t <= 168]),
                "over_7_days": len([t for t in usage_times if t > 168]),
            }

            usage_time_analysis = {
                "average_usage_time": sum(usage_times) / len(usage_times)
                if usage_times
                else 0,
                "quick_usage_count": quick_usage_count,
                "delayed_usage_count": delayed_usage_count,
                "usage_time_distribution": usage_time_distribution,
                "median_usage_time": sorted(usage_times)[len(usage_times) // 2]
                if usage_times
                else 0,
            }

            return usage_time_analysis

        except Exception as e:
            logger.error(f"åˆ†æç»‘å®šç ä½¿ç”¨æ—¶é—´å¤±è´¥: {e}")
            return {}
            logger.error(f"æŒ‰ç±»åˆ«åˆ†æå•†æˆ·å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _categorize_merchant_performance(
        merchant_metrics: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """å•†æˆ·è¡¨ç°åˆ†å±‚"""
        try:
            if not merchant_metrics:
                return {}

            # æŒ‰äº¤äº’æ•°é‡åˆ†å±‚
            interactions = [m["total_interactions"] for m in merchant_metrics]
            interactions.sort(reverse=True)

            # è®¡ç®—åˆ†ä½æ•°
            total_merchants = len(interactions)
            top_20_percent = max(1, total_merchants // 5)
            top_50_percent = max(1, total_merchants // 2)

            performance_tiers = {
                "top_performers": {
                    "count": top_20_percent,
                    "min_interactions": interactions[top_20_percent - 1]
                    if top_20_percent <= len(interactions)
                    else 0,
                    "merchants": merchant_metrics[:top_20_percent],
                },
                "good_performers": {
                    "count": top_50_percent - top_20_percent,
                    "min_interactions": interactions[top_50_percent - 1]
                    if top_50_percent <= len(interactions)
                    else 0,
                    "merchants": merchant_metrics[top_20_percent:top_50_percent],
                },
                "average_performers": {
                    "count": total_merchants - top_50_percent,
                    "merchants": merchant_metrics[top_50_percent:],
                },
            }

            return performance_tiers

        except Exception as e:
            logger.error(f"å•†æˆ·è¡¨ç°åˆ†å±‚å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_order_prices(orders: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æè®¢å•ä»·æ ¼"""
        try:
            prices = [
                float(order.get("price", 0)) for order in orders if order.get("price")
            ]

            if not prices:
                return {"note": "æ²¡æœ‰ä»·æ ¼æ•°æ®"}

            prices.sort()
            total_orders = len(prices)

            price_analysis = {
                "total_revenue": sum(prices),
                "average_price": sum(prices) / total_orders,
                "median_price": prices[total_orders // 2],
                "min_price": min(prices),
                "max_price": max(prices),
                "price_range": max(prices) - min(prices),
            }

            return price_analysis

        except Exception as e:
            logger.error(f"åˆ†æè®¢å•ä»·æ ¼å¤±è´¥: {e}")
            return {}

    @staticmethod
    async def _analyze_code_usage_time(codes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æç»‘å®šç ä½¿ç”¨æ—¶é—´"""
        try:
            usage_times = []

            for code in codes:
                if code["is_used"] and code.get("used_at"):
                    created_at = datetime.fromisoformat(code["created_at"])
                    used_at = datetime.fromisoformat(code["used_at"])
                    usage_time = (used_at - created_at).total_seconds() / 3600  # è½¬æ¢ä¸ºå°æ—¶
                    usage_times.append(usage_time)

            if not usage_times:
                return {"note": "æ²¡æœ‰ä½¿ç”¨æ—¶é—´æ•°æ®"}

            usage_times.sort()
            total_used = len(usage_times)

            usage_analysis = {
                "average_usage_time_hours": sum(usage_times) / total_used,
                "median_usage_time_hours": usage_times[total_used // 2],
                "fastest_usage_hours": min(usage_times),
                "slowest_usage_hours": max(usage_times),
                "quick_usage_count": len([t for t in usage_times if t <= 1]),  # 1å°æ—¶å†…ä½¿ç”¨
                "delayed_usage_count": len(
                    [t for t in usage_times if t > 12]
                ),  # 12å°æ—¶åä½¿ç”¨
            }

            return usage_analysis

        except Exception as e:
            logger.error(f"åˆ†æç»‘å®šç ä½¿ç”¨æ—¶é—´å¤±è´¥: {e}")
            return {}


class StatisticsFormatter:
    """
    ç»Ÿè®¡æ•°æ®æ ¼å¼åŒ–å™¨
    å°†ç»Ÿè®¡æ•°æ®æ ¼å¼åŒ–ä¸ºç”¨æˆ·å‹å¥½çš„æ–‡æœ¬æ ¼å¼
    """

    @staticmethod
    async def format_comprehensive_stats(stats_result: StatsResult) -> str:
        """
        æ ¼å¼åŒ–ç»¼åˆç»Ÿè®¡æ•°æ®ï¼ˆä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿï¼‰

        Args:
            stats_result: ç»Ÿè®¡ç»“æœå¯¹è±¡

        Returns:
            æ ¼å¼åŒ–çš„ç»Ÿè®¡æ–‡æœ¬
        """
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            # ä½¿ç”¨æ¨¡æ¿ç³»ç»Ÿ
            template = await template_manager.get_template(
                "stats_comprehensive_report",
                default="""
ğŸ“Š {period_name}ç»¼åˆç»Ÿè®¡æŠ¥å‘Š

â° ç»Ÿè®¡æ—¶é—´: {generated_at}
ğŸ“… æ•°æ®èŒƒå›´: {start_date} è‡³ {end_date}

ğŸ”˜ æŒ‰é’®æ•°æ®:
â€¢ æ€»ç‚¹å‡»æ•°: {total_clicks:,}
â€¢ ç‹¬ç«‹ç”¨æˆ·: {unique_users:,}
â€¢ å¹³å‡ç‚¹å‡»: {avg_clicks:.1f}

ğŸ‘¥ ç”¨æˆ·æ•°æ®:
â€¢ æ€»æ´»åŠ¨æ•°: {total_activities:,}
â€¢ æ´»è·ƒç”¨æˆ·: {active_users:,}

ğŸª å•†æˆ·æ•°æ®:
â€¢ æ€»å•†æˆ·æ•°: {total_merchants:,}
â€¢ æ´»è·ƒå•†æˆ·: {active_merchants:,}

ğŸ“‹ è®¢å•æ•°æ®:
â€¢ æ€»è®¢å•æ•°: {total_orders:,}
â€¢ å®Œæˆè®¢å•: {completed_orders:,}
â€¢ å®Œæˆç‡: {completion_rate:.1f}%

ğŸ”‘ ç»‘å®šç æ•°æ®:
â€¢ æ€»ç”Ÿæˆæ•°: {total_generated:,}
â€¢ ä½¿ç”¨ç‡: {usage_rate:.1f}%

ğŸ“ˆ ç³»ç»Ÿå¥åº·åº¦:
â€¢ ç»¼åˆè¯„åˆ†: {overall_score:.1f}/100
â€¢ å•†æˆ·æ¿€æ´»ç‡: {merchant_activation_rate:.1f}%
â€¢ ç”¨æˆ·å‚ä¸åº¦: {user_engagement_rate:.1f}%
â€¢ è®¢å•è½¬åŒ–ç‡: {order_conversion_rate:.1f}%
""",
            )

            # æ ¼å¼åŒ–æ•°æ®
            formatted_text = template.format(
                period_name=time_range.period_name,
                generated_at=stats_result.generated_at.strftime("%Y-%m-%d %H:%M:%S"),
                start_date=time_range.start_date.strftime("%Y-%m-%d"),
                end_date=time_range.end_date.strftime("%Y-%m-%d"),
                total_clicks=data.get("button_clicks", {}).get("total_clicks", 0),
                unique_users=data.get("button_clicks", {}).get("unique_users", 0),
                avg_clicks=data.get("button_clicks", {}).get(
                    "average_clicks_per_user", 0
                ),
                total_activities=data.get("user_activity", {}).get(
                    "total_activities", 0
                ),
                active_users=data.get("user_activity", {}).get("active_users", 0),
                total_merchants=data.get("merchant_performance", {}).get(
                    "total_merchants", 0
                ),
                active_merchants=data.get("merchant_performance", {}).get(
                    "active_merchants", 0
                ),
                total_orders=data.get("order_analytics", {}).get("total_orders", 0),
                completed_orders=data.get("order_analytics", {}).get(
                    "completed_orders", 0
                ),
                completion_rate=data.get("order_analytics", {}).get(
                    "completion_rate", 0
                ),
                total_generated=data.get("binding_codes", {}).get("total_generated", 0),
                usage_rate=data.get("binding_codes", {}).get("usage_rate", 0),
                overall_score=data.get("system_health", {}).get("overall_score", 0),
                merchant_activation_rate=data.get("system_health", {}).get(
                    "merchant_activation_rate", 0
                ),
                user_engagement_rate=data.get("system_health", {}).get(
                    "user_engagement_rate", 0
                ),
                order_conversion_rate=data.get("system_health", {}).get(
                    "order_conversion_rate", 0
                ),
            )

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç»¼åˆç»Ÿè®¡å¤±è´¥: {e}")
            error_template = await template_manager.get_template(
                "error_stats_format_failed", default="âŒ æ ¼å¼åŒ–ç»Ÿè®¡æ•°æ®å¤±è´¥"
            )
            return error_template

    @staticmethod
    def format_button_stats(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–æŒ‰é’®ç»Ÿè®¡æ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            formatted_text = f"""
ğŸ”˜ {time_range.period_name}æŒ‰é’®ç‚¹å‡»ç»Ÿè®¡

ğŸ“Š åŸºç¡€æŒ‡æ ‡:
â€¢ æ€»ç‚¹å‡»æ•°: {data.get('basic_metrics', {}).get('total_clicks', 0):,}
â€¢ ç‹¬ç«‹ç”¨æˆ·: {data.get('basic_metrics', {}).get('unique_users', 0):,}
â€¢ å¹³å‡ç‚¹å‡»: {data.get('basic_metrics', {}).get('average_clicks_per_user', 0):.1f}
â€¢ ç‚¹å‡»ç‡: {data.get('basic_metrics', {}).get('click_through_rate', 0):.1f}%

ğŸ† çƒ­é—¨æŒ‰é’®æ’è¡Œ:
            """

            # æ·»åŠ æŒ‰é’®æ’è¡Œ
            button_performance = data.get("button_performance", {})
            sorted_buttons = sorted(
                button_performance.items(),
                key=lambda x: x[1].get("clicks", 0),
                reverse=True,
            )

            for i, (button_id, stats) in enumerate(sorted_buttons[:10], 1):
                formatted_text += f"\n{i}. {button_id}"
                formatted_text += f"\n   ç‚¹å‡»: {stats.get('clicks', 0)} | ç”¨æˆ·: {stats.get('unique_users', 0)}"

            # æ·»åŠ è¶‹åŠ¿åˆ†æ
            trend_analysis = data.get("trend_analysis", {})
            if trend_analysis:
                trend_emoji = (
                    "ğŸ“ˆ"
                    if trend_analysis.get("trend") == "increasing"
                    else "ğŸ“‰"
                    if trend_analysis.get("trend") == "decreasing"
                    else "â¡ï¸"
                )
                formatted_text += f"\n\n{trend_emoji} è¶‹åŠ¿åˆ†æ:"
                formatted_text += f"\nâ€¢ è¶‹åŠ¿: {trend_analysis.get('trend', 'æœªçŸ¥')}"
                formatted_text += (
                    f"\nâ€¢ å¢é•¿ç‡: {trend_analysis.get('growth_rate', 0):.1f}%"
                )

            # æ·»åŠ é«˜å³°æ—¶æ®µ
            peak_hours = data.get("peak_hours", {})
            if peak_hours.get("peak_hour"):
                formatted_text += f"\n\nâ° æ´»è·ƒæ—¶æ®µ:"
                formatted_text += f"\nâ€¢ é«˜å³°æ—¶æ®µ: {peak_hours.get('peak_hour')} ({peak_hours.get('peak_clicks', 0)}æ¬¡ç‚¹å‡»)"
                formatted_text += f"\nâ€¢ ä½è°·æ—¶æ®µ: {peak_hours.get('quiet_hour')} ({peak_hours.get('quiet_clicks', 0)}æ¬¡ç‚¹å‡»)"

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æŒ‰é’®ç»Ÿè®¡å¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–æŒ‰é’®ç»Ÿè®¡å¤±è´¥"

    @staticmethod
    def format_merchant_stats(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–å•†æˆ·ç»Ÿè®¡æ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            formatted_text = f"""
ğŸª {time_range.period_name}å•†æˆ·è¡¨ç°ç»Ÿè®¡

ğŸ“Š åŸºç¡€æŒ‡æ ‡:
â€¢ æ€»å•†æˆ·æ•°: {data.get('basic_metrics', {}).get('total_merchants', 0):,}
â€¢ æ´»è·ƒå•†æˆ·: {data.get('basic_metrics', {}).get('active_merchants', 0):,}
â€¢ å¹³å‡äº¤äº’æ•°: {data.get('basic_metrics', {}).get('average_interactions_per_merchant', 0):.1f}
â€¢ å¹³å‡è®¢å•æ•°: {data.get('basic_metrics', {}).get('average_orders_per_merchant', 0):.1f}

ğŸ† å•†æˆ·æ’è¡Œæ¦œ:
            """

            # æ·»åŠ å•†æˆ·æ’è¡Œ
            merchant_rankings = data.get("merchant_rankings", [])
            for i, merchant in enumerate(merchant_rankings[:10], 1):
                formatted_text += f"\n{i}. {merchant.get('merchant_name', 'æœªçŸ¥å•†æˆ·')}"
                formatted_text += f"\n   äº¤äº’: {merchant.get('total_interactions', 0)} | è®¢å•: {merchant.get('total_orders', 0)} | è½¬åŒ–ç‡: {merchant.get('conversion_rate', 0):.1f}%"

            # æ·»åŠ åœ°åŒºåˆ†æ
            region_analysis = data.get("region_analysis", {})
            if region_analysis:
                formatted_text += f"\n\nğŸŒ åœ°åŒºåˆ†å¸ƒ:"
                sorted_regions = sorted(
                    region_analysis.items(),
                    key=lambda x: x[1].get("merchant_count", 0),
                    reverse=True,
                )
                for region, stats in sorted_regions[:5]:
                    formatted_text += f"\nâ€¢ {region}: {stats.get('merchant_count', 0)}ä¸ªå•†æˆ· (å¹³å‡{stats.get('avg_interactions', 0):.1f}æ¬¡äº¤äº’)"

            # æ·»åŠ ç±»åˆ«åˆ†æ
            category_analysis = data.get("category_analysis", {})
            if category_analysis:
                formatted_text += f"\n\nğŸ·ï¸ ç±»åˆ«åˆ†å¸ƒ:"
                sorted_categories = sorted(
                    category_analysis.items(),
                    key=lambda x: x[1].get("merchant_count", 0),
                    reverse=True,
                )
                for category, stats in sorted_categories[:5]:
                    formatted_text += f"\nâ€¢ {category}: {stats.get('merchant_count', 0)}ä¸ªå•†æˆ· (å¹³å‡{stats.get('avg_orders', 0):.1f}ä¸ªè®¢å•)"

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–å•†æˆ·ç»Ÿè®¡å¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–å•†æˆ·ç»Ÿè®¡å¤±è´¥"

    @staticmethod
    def format_user_activity_stats(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡æ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            formatted_text = f"""
ğŸ‘¥ {time_range.period_name}ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡

ğŸ“Š åŸºç¡€æŒ‡æ ‡:
â€¢ æ€»æ´»åŠ¨æ•°: {data.get('basic_metrics', {}).get('total_activities', 0):,}
â€¢ æ´»è·ƒç”¨æˆ·: {data.get('basic_metrics', {}).get('active_users', 0):,}
â€¢ å¹³å‡æ´»åŠ¨: {data.get('basic_metrics', {}).get('average_activities_per_user', 0):.1f}

ğŸ† æœ€æ´»è·ƒç”¨æˆ·:
            """

            # æœ€æ´»è·ƒç”¨æˆ·æ’è¡Œ
            top_users = data.get("top_users", [])
            for i, user in enumerate(top_users[:10], 1):
                formatted_text += f"\n{i}. ç”¨æˆ· {user.get('user_id', 'æœªçŸ¥')}: {user.get('activity_count', 0)}æ¬¡æ´»åŠ¨"

            # æ´»åŠ¨ç±»å‹åˆ†å¸ƒ
            activity_distribution = data.get("activity_distribution", {})
            if activity_distribution:
                formatted_text += "\n\nğŸ“‹ æ´»åŠ¨ç±»å‹åˆ†å¸ƒ:"
                sorted_activities = sorted(
                    activity_distribution.items(), key=lambda x: x[1], reverse=True
                )
                for action_type, count in sorted_activities[:5]:
                    formatted_text += f"\nâ€¢ {action_type}: {count:,}æ¬¡"

            # ç”¨æˆ·åˆ†å±‚
            user_segments = data.get("user_segments", {})
            if user_segments:
                formatted_text += f"\n\nğŸ‘¥ ç”¨æˆ·åˆ†å±‚:"
                formatted_text += (
                    f"\nâ€¢ é«˜æ´»è·ƒç”¨æˆ·: {user_segments.get('high_activity', 0):,}"
                )
                formatted_text += (
                    f"\nâ€¢ ä¸­æ´»è·ƒç”¨æˆ·: {user_segments.get('medium_activity', 0):,}"
                )
                formatted_text += f"\nâ€¢ ä½æ´»è·ƒç”¨æˆ·: {user_segments.get('low_activity', 0):,}"

            # ç•™å­˜åˆ†æ
            retention_analysis = data.get("retention_analysis", {})
            if retention_analysis and retention_analysis.get("note"):
                formatted_text += f"\n\nğŸ“ˆ ç•™å­˜åˆ†æ:"
                formatted_text += f"\nâ€¢ {retention_analysis.get('note', 'æš‚æ— æ•°æ®')}"

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡å¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡å¤±è´¥"

    @staticmethod
    def format_order_analytics(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–è®¢å•åˆ†ææ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            formatted_text = f"""
ğŸ“‹ {time_range.period_name}è®¢å•åˆ†æç»Ÿè®¡

ğŸ“Š åŸºç¡€æŒ‡æ ‡:
â€¢ æ€»è®¢å•æ•°: {data.get('basic_metrics', {}).get('total_orders', 0):,}
â€¢ å®Œæˆè®¢å•: {data.get('basic_metrics', {}).get('completed_orders', 0):,}
â€¢ å¾…å¤„ç†è®¢å•: {data.get('basic_metrics', {}).get('pending_orders', 0):,}
â€¢ å®Œæˆç‡: {data.get('basic_metrics', {}).get('completion_rate', 0):.1f}%

ğŸ“ˆ è®¢å•ç±»å‹åˆ†å¸ƒ:
            """

            # è®¢å•ç±»å‹åˆ†å¸ƒ
            order_type_distribution = data.get("order_type_distribution", {})
            for order_type, count in sorted(
                order_type_distribution.items(), key=lambda x: x[1], reverse=True
            ):
                formatted_text += f"\nâ€¢ {order_type}: {count:,}ä¸ªè®¢å•"

            # å•†æˆ·è®¢å•åˆ†å¸ƒï¼ˆå‰10åï¼‰
            merchant_distribution = data.get("merchant_distribution", {})
            if merchant_distribution:
                formatted_text += f"\n\nğŸª å•†æˆ·è®¢å•æ’è¡Œ:"
                sorted_merchants = sorted(
                    merchant_distribution.items(), key=lambda x: x[1], reverse=True
                )
                for i, (merchant_id, count) in enumerate(sorted_merchants[:10], 1):
                    formatted_text += f"\n{i}. å•†æˆ· {merchant_id}: {count:,}ä¸ªè®¢å•"

            # æ—¶é—´åˆ†å¸ƒåˆ†æ
            daily_distribution = data.get("daily_distribution", {})
            if daily_distribution:
                formatted_text += f"\n\nğŸ“… æ¯æ—¥è®¢å•è¶‹åŠ¿:"
                sorted_days = sorted(
                    daily_distribution.items(), key=lambda x: x[0], reverse=True
                )
                for date, count in sorted_days[:7]:  # æ˜¾ç¤ºæœ€è¿‘7å¤©
                    formatted_text += f"\nâ€¢ {date}: {count:,}ä¸ªè®¢å•"

            # ä»·æ ¼åˆ†æ
            price_analysis = data.get("price_analysis", {})
            if price_analysis and price_analysis.get("total_orders_with_price", 0) > 0:
                formatted_text += f"\n\nğŸ’° ä»·æ ¼åˆ†æ:"
                formatted_text += (
                    f"\nâ€¢ å¹³å‡ä»·æ ¼: Â¥{price_analysis.get('average_price', 0):.2f}"
                )
                formatted_text += (
                    f"\nâ€¢ æ€»æ”¶å…¥: Â¥{price_analysis.get('total_revenue', 0):.2f}"
                )
                formatted_text += (
                    f"\nâ€¢ æœ‰ä»·æ ¼è®¢å•: {price_analysis.get('total_orders_with_price', 0):,}"
                )

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–è®¢å•åˆ†æå¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–è®¢å•åˆ†æå¤±è´¥"

    @staticmethod
    def format_binding_code_analytics(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–ç»‘å®šç åˆ†ææ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            formatted_text = f"""
ğŸ”‘ {time_range.period_name}ç»‘å®šç åˆ†æç»Ÿè®¡

ğŸ“Š åŸºç¡€æŒ‡æ ‡:
â€¢ æ€»ç”Ÿæˆæ•°: {data.get('basic_metrics', {}).get('total_generated', 0):,}
â€¢ å·²ä½¿ç”¨æ•°: {data.get('basic_metrics', {}).get('total_used', 0):,}
â€¢ å·²è¿‡æœŸæ•°: {data.get('basic_metrics', {}).get('total_expired', 0):,}
â€¢ ä½¿ç”¨ç‡: {data.get('basic_metrics', {}).get('usage_rate', 0):.1f}%
â€¢ è¿‡æœŸç‡: {data.get('basic_metrics', {}).get('expiry_rate', 0):.1f}%

ğŸ“ˆ ä½¿ç”¨è¶‹åŠ¿:
            """

            # æ¯æ—¥ç”Ÿæˆè¶‹åŠ¿
            daily_generation = data.get("daily_generation", {})
            if daily_generation:
                formatted_text += f"\n\nğŸ“… æ¯æ—¥ç”Ÿæˆè¶‹åŠ¿:"
                sorted_days = sorted(
                    daily_generation.items(), key=lambda x: x[0], reverse=True
                )
                for date, count in sorted_days[:7]:  # æ˜¾ç¤ºæœ€è¿‘7å¤©
                    formatted_text += f"\nâ€¢ {date}: {count:,}ä¸ªç»‘å®šç "

            # æ¯æ—¥ä½¿ç”¨è¶‹åŠ¿
            daily_usage = data.get("daily_usage", {})
            if daily_usage:
                formatted_text += f"\n\nâœ… æ¯æ—¥ä½¿ç”¨è¶‹åŠ¿:"
                sorted_usage_days = sorted(
                    daily_usage.items(), key=lambda x: x[0], reverse=True
                )
                for date, count in sorted_usage_days[:7]:  # æ˜¾ç¤ºæœ€è¿‘7å¤©
                    formatted_text += f"\nâ€¢ {date}: {count:,}ä¸ªç»‘å®šç è¢«ä½¿ç”¨"

            # ä½¿ç”¨æ—¶é—´åˆ†æ
            usage_time_analysis = data.get("usage_time_analysis", {})
            if usage_time_analysis:
                formatted_text += f"\n\nâ±ï¸ ä½¿ç”¨æ—¶é—´åˆ†æ:"
                if usage_time_analysis.get("average_usage_time"):
                    formatted_text += f"\nâ€¢ å¹³å‡ä½¿ç”¨æ—¶é—´: {usage_time_analysis.get('average_usage_time', 0):.1f}å°æ—¶"
                if usage_time_analysis.get("quick_usage_count"):
                    formatted_text += f"\nâ€¢ å¿«é€Ÿä½¿ç”¨(1å°æ—¶å†…): {usage_time_analysis.get('quick_usage_count', 0):,}ä¸ª"
                if usage_time_analysis.get("delayed_usage_count"):
                    formatted_text += f"\nâ€¢ å»¶è¿Ÿä½¿ç”¨(24å°æ—¶å): {usage_time_analysis.get('delayed_usage_count', 0):,}ä¸ª"

            # æ•´ä½“ç»Ÿè®¡
            overall_stats = data.get("overall_stats", {})
            if overall_stats:
                formatted_text += f"\n\nğŸ“Š å†å²æ€»è§ˆ:"
                formatted_text += (
                    f"\nâ€¢ å†å²æ€»ç”Ÿæˆ: {overall_stats.get('total_generated', 0):,}"
                )
                formatted_text += f"\nâ€¢ å†å²æ€»ä½¿ç”¨: {overall_stats.get('total_used', 0):,}"
                formatted_text += (
                    f"\nâ€¢ å†å²ä½¿ç”¨ç‡: {overall_stats.get('usage_rate', 0):.1f}%"
                )

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç»‘å®šç åˆ†æå¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–ç»‘å®šç åˆ†æå¤±è´¥"

    @staticmethod
    def format_system_health_analytics(stats_result: StatsResult) -> str:
        """æ ¼å¼åŒ–ç³»ç»Ÿå¥åº·åº¦åˆ†ææ•°æ®"""
        try:
            data = stats_result.data
            time_range = stats_result.time_range

            # è·å–å¥åº·åº¦è¯„åˆ†
            health_score = data.get("health_score", {})
            overall_score = health_score.get("overall_score", 0)

            # æ ¹æ®è¯„åˆ†ç¡®å®šå¥åº·çŠ¶æ€
            if overall_score >= 80:
                health_status = "ğŸŸ¢ ä¼˜ç§€"
                health_emoji = "ğŸŸ¢"
            elif overall_score >= 60:
                health_status = "ğŸŸ¡ è‰¯å¥½"
                health_emoji = "ğŸŸ¡"
            elif overall_score >= 40:
                health_status = "ğŸŸ  ä¸€èˆ¬"
                health_emoji = "ğŸŸ "
            else:
                health_status = "ğŸ”´ éœ€è¦æ”¹è¿›"
                health_emoji = "ğŸ”´"

            formatted_text = f"""
ğŸ“ˆ {time_range.period_name}ç³»ç»Ÿå¥åº·åº¦åˆ†æ

{health_emoji} æ•´ä½“å¥åº·çŠ¶æ€: {health_status} ({overall_score:.1f}/100)

ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡:
â€¢ å•†æˆ·æ¿€æ´»ç‡: {health_score.get('merchant_activation_rate', 0):.1f}%
â€¢ ç”¨æˆ·å‚ä¸åº¦: {health_score.get('user_engagement_rate', 0):.1f}%
â€¢ è®¢å•è½¬åŒ–ç‡: {health_score.get('order_conversion_rate', 0):.1f}%
â€¢ ç»‘å®šç æ•ˆç‡: {health_score.get('binding_code_efficiency', 0):.1f}%

ğŸ”¢ ç³»ç»ŸæŒ‡æ ‡:
â€¢ æ€»å•†æˆ·æ•°: {data.get('system_metrics', {}).get('total_merchants', 0):,}
â€¢ æ´»è·ƒå•†æˆ·: {data.get('system_metrics', {}).get('active_merchants', 0):,}
â€¢ æ€»ç”¨æˆ·æ•°: {data.get('system_metrics', {}).get('total_users', 0):,}
â€¢ æ´»è·ƒç”¨æˆ·: {data.get('system_metrics', {}).get('active_users', 0):,}
â€¢ æ€»è®¢å•æ•°: {data.get('system_metrics', {}).get('total_orders', 0):,}

âš¡ æ€§èƒ½æŒ‡æ ‡:
â€¢ å¹¶å‘ç”¨æˆ·æ•°: {data.get('performance_metrics', {}).get('concurrent_users', 0):,}
â€¢ ç³»ç»Ÿæ­£å¸¸è¿è¡Œæ—¶é—´: {data.get('performance_metrics', {}).get('uptime_percentage', 0):.1f}%
            """

            # é”™è¯¯åˆ†æ
            error_analysis = data.get("error_analysis", {})
            if error_analysis:
                error_rate = error_analysis.get("error_rate", 0)
                error_emoji = "ğŸŸ¢" if error_rate < 1 else "ğŸŸ¡" if error_rate < 5 else "ğŸ”´"
                formatted_text += f"\n\n{error_emoji} é”™è¯¯åˆ†æ:"
                formatted_text += f"\nâ€¢ é”™è¯¯ç‡: {error_rate:.2f}%"
                formatted_text += f"\nâ€¢ é”™è¯¯æ€»æ•°: {error_analysis.get('total_errors', 0):,}"

            # ç³»ç»Ÿå»ºè®®
            formatted_text += f"\n\nğŸ’¡ ç³»ç»Ÿå»ºè®®:"
            if overall_score >= 80:
                formatted_text += f"\nâ€¢ ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œç»§ç»­ä¿æŒå½“å‰çŠ¶æ€"
            elif overall_score >= 60:
                formatted_text += f"\nâ€¢ ç³»ç»Ÿæ•´ä½“è‰¯å¥½ï¼Œå¯ä¼˜åŒ–ç”¨æˆ·å‚ä¸åº¦"
            elif overall_score >= 40:
                formatted_text += f"\nâ€¢ å»ºè®®å…³æ³¨å•†æˆ·æ¿€æ´»å’Œç”¨æˆ·è½¬åŒ–"
            else:
                formatted_text += f"\nâ€¢ ç³»ç»Ÿéœ€è¦é‡ç‚¹ä¼˜åŒ–ï¼Œå»ºè®®æ£€æŸ¥æ ¸å¿ƒåŠŸèƒ½"

            return formatted_text.strip()

        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ç³»ç»Ÿå¥åº·åº¦åˆ†æå¤±è´¥: {e}")
            return "âŒ æ ¼å¼åŒ–ç³»ç»Ÿå¥åº·åº¦åˆ†æå¤±è´¥"


# åˆ›å»ºå…¨å±€ç»Ÿè®¡å¼•æ“å®ä¾‹
statistics_engine = StatisticsEngine()
statistics_formatter = StatisticsFormatter()
